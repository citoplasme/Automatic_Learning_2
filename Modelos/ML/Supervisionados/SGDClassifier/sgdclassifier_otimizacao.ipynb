{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Aprendizagem Automática II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procura de Exoplanetas no Espaço através da Emissão de Luz de Estrelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, DecomposeResult\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, classification_report, precision_score, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn import linear_model\n",
    "from scipy import ndimage, fft\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo é o carregamento dos dados, de modo a treinar e, consequentemente, testar o modelo gerado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pd.read_csv(\"../../../../Dados/dados_treino.csv\")\n",
    "teste = pd.read_csv(\"../../../../Dados/dados_teste.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o carregamento dos mesmos, é necessário dividir os registos em *labels* e *features*. Note-se que esta divisão deve ser efetuada tanto no conjunto de treino, como no de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = treino.loc[:, treino.columns != 'LABEL'].values\n",
    "y_train = treino.LABEL.values\n",
    "\n",
    "X_test = teste.loc[:, teste.columns != 'LABEL'].values\n",
    "y_test = teste.LABEL.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados obtidos com um classificador linear *SGD* no momento do teste das tranformações efetuadas aos dados para classificação, este tipo de modelo mostrou-se merecedor de um estudo extra. Assim, de modo a otimizar o mesmo, é necessário instanciar uma variável com o classificador pretendido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.SGDClassifier(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma a otimizar os parâmetros do modelo, estes devem ser definidos na forma de dicionário. Neste caso, foi optado pelo teste de várias combinações, vendo qual a que melhores resultados traria ao problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {'epsilon': [0.001, 0.01, 0.1, 1, 0.0001, 0.00001], \n",
    "              'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "              'loss': ['hinge', 'log', 'perceptron', 'squared_loss', 'huber'],\n",
    "              'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "              'alpha': [0.001, 0.0005, 0.0001, 0.00005, 0.00001],\n",
    "              'eta0': [0.1, 0.001, 0.0001, 0.00001],\n",
    "              'shuffle': [True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi tirado proveito do método *GridSearchCV*, permitindo uma pesquisa em grelha dentro das combinações de parâmetros pretendidas, em que exista uma validação em cruz. Neste caso, foi optada por uma validação cruzada de 10 subconjuntos, sendo a métrica de *accuracy* a métrica a observar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gd_sr = GridSearchCV(estimator=model,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=10,\n",
    "                     n_jobs=-1,\n",
    "                     verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo o modelo definido e pronto a efetuar a procura, apenas é necessário aplicar o método *fit* com o conjunto de dados de treino. Não faria sentido aplicar a validação cruzada aos dados de teste juntamente com os de treino, já que o modelo ficaria demasiado ajustado aos dados, perdendo a capacidade de classificar corretamente novos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 14400 candidates, totalling 144000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 60.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed: 89.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 110.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed: 146.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 163.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4885 tasks      | elapsed: 213.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5816 tasks      | elapsed: 255.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6829 tasks      | elapsed: 314.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7922 tasks      | elapsed: 361.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9097 tasks      | elapsed: 406.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10352 tasks      | elapsed: 474.8min\n",
      "[Parallel(n_jobs=-1)]: Done 11689 tasks      | elapsed: 556.0min\n",
      "[Parallel(n_jobs=-1)]: Done 13106 tasks      | elapsed: 620.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14605 tasks      | elapsed: 693.7min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 812.9min\n",
      "[Parallel(n_jobs=-1)]: Done 17845 tasks      | elapsed: 899.3min\n",
      "[Parallel(n_jobs=-1)]: Done 19586 tasks      | elapsed: 987.5min\n",
      "[Parallel(n_jobs=-1)]: Done 21409 tasks      | elapsed: 1077.5min\n",
      "[Parallel(n_jobs=-1)]: Done 23312 tasks      | elapsed: 1153.8min\n",
      "[Parallel(n_jobs=-1)]: Done 25297 tasks      | elapsed: 1250.7min\n",
      "[Parallel(n_jobs=-1)]: Done 27362 tasks      | elapsed: 1336.0min\n",
      "[Parallel(n_jobs=-1)]: Done 29509 tasks      | elapsed: 1421.1min\n",
      "[Parallel(n_jobs=-1)]: Done 31736 tasks      | elapsed: 1512.6min\n",
      "[Parallel(n_jobs=-1)]: Done 34045 tasks      | elapsed: 1588.9min\n",
      "[Parallel(n_jobs=-1)]: Done 36434 tasks      | elapsed: 1688.7min\n",
      "[Parallel(n_jobs=-1)]: Done 38905 tasks      | elapsed: 1785.8min\n",
      "[Parallel(n_jobs=-1)]: Done 41456 tasks      | elapsed: 1915.6min\n",
      "[Parallel(n_jobs=-1)]: Done 44089 tasks      | elapsed: 2032.0min\n",
      "[Parallel(n_jobs=-1)]: Done 46802 tasks      | elapsed: 2181.3min\n",
      "[Parallel(n_jobs=-1)]: Done 49597 tasks      | elapsed: 2297.1min\n",
      "[Parallel(n_jobs=-1)]: Done 52472 tasks      | elapsed: 2408.1min\n",
      "[Parallel(n_jobs=-1)]: Done 55429 tasks      | elapsed: 2506.7min\n",
      "[Parallel(n_jobs=-1)]: Done 58466 tasks      | elapsed: 2610.8min\n",
      "[Parallel(n_jobs=-1)]: Done 61585 tasks      | elapsed: 2707.0min\n",
      "[Parallel(n_jobs=-1)]: Done 64784 tasks      | elapsed: 2846.4min\n",
      "[Parallel(n_jobs=-1)]: Done 68065 tasks      | elapsed: 2956.4min\n",
      "[Parallel(n_jobs=-1)]: Done 71426 tasks      | elapsed: 3103.7min\n",
      "[Parallel(n_jobs=-1)]: Done 74869 tasks      | elapsed: 3279.9min\n",
      "[Parallel(n_jobs=-1)]: Done 78392 tasks      | elapsed: 3429.9min\n",
      "[Parallel(n_jobs=-1)]: Done 81997 tasks      | elapsed: 3535.5min\n",
      "[Parallel(n_jobs=-1)]: Done 85682 tasks      | elapsed: 3647.6min\n",
      "[Parallel(n_jobs=-1)]: Done 89449 tasks      | elapsed: 3788.2min\n",
      "[Parallel(n_jobs=-1)]: Done 93296 tasks      | elapsed: 3933.9min\n",
      "[Parallel(n_jobs=-1)]: Done 97225 tasks      | elapsed: 4103.0min\n",
      "[Parallel(n_jobs=-1)]: Done 101234 tasks      | elapsed: 4247.6min\n",
      "[Parallel(n_jobs=-1)]: Done 105325 tasks      | elapsed: 4490.6min\n",
      "[Parallel(n_jobs=-1)]: Done 109496 tasks      | elapsed: 4608.1min\n",
      "[Parallel(n_jobs=-1)]: Done 113749 tasks      | elapsed: 4754.4min\n",
      "[Parallel(n_jobs=-1)]: Done 118082 tasks      | elapsed: 4897.3min\n",
      "[Parallel(n_jobs=-1)]: Done 122497 tasks      | elapsed: 5073.1min\n",
      "[Parallel(n_jobs=-1)]: Done 126992 tasks      | elapsed: 5271.3min\n",
      "[Parallel(n_jobs=-1)]: Done 131569 tasks      | elapsed: 5497.4min\n",
      "[Parallel(n_jobs=-1)]: Done 136226 tasks      | elapsed: 5703.6min\n",
      "[Parallel(n_jobs=-1)]: Done 140965 tasks      | elapsed: 5857.2min\n",
      "[Parallel(n_jobs=-1)]: Done 144000 out of 144000 | elapsed: 5949.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='hinge', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5,\n",
       "                                     random_state=None, shuffle=True, tol=0.001,\n",
       "                                     validation_fraction=0.1...\n",
       "             param_grid={'alpha': [0.001, 0.0005, 0.0001, 5e-05, 1e-05],\n",
       "                         'epsilon': [0.001, 0.01, 0.1, 1, 0.0001, 1e-05],\n",
       "                         'eta0': [0.1, 0.001, 0.0001, 1e-05],\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'loss': ['hinge', 'log', 'perceptron', 'squared_loss',\n",
       "                                  'huber'],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet'],\n",
       "                         'shuffle': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_sr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se pode ver em seguida, os melhores parâmetros de entre os testados são *alpha* com valor 0.0001 e *epsilon* a 1. Já *eta0*, ou seja, o valor inicial para a taxa de aprendizagem, com valor de 0.00001, sendo a taxa de aprendizagem *invscaling*. Além disso, a *loss* do modelo é *huber*. O conjunto de treino foi baralhado a cada época e o termo de regularização (*penalty*) que melhores resultados trouxe foi *elasticnet*, podendo trazer alguma *feature selection* ao modelo, segundo a [documentação](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'epsilon': 1, 'eta0': 1e-05, 'learning_rate': 'invscaling', 'loss': 'huber', 'penalty': 'elasticnet', 'shuffle': True}\n"
     ]
    }
   ],
   "source": [
    "best_parameters = gd_sr.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor resultado obtido para a pesquisa em grelha, com os parâmetros acima mencionados, permitiu uma *accuracy* de sensivelmente 99.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9939068474588856\n"
     ]
    }
   ],
   "source": [
    "best_result = gd_sr.best_score_\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conhecidos os melhores parâmetros para este modelo, é necessário ver de que forma se comporta na classificação do conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gd_sr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando as métricas obtidas pela predição dos registos de teste, é notório que que a precisão da classe minoritária subiu quando em comparação com o modelo original (tinha valor de 50%), mantendo-se o *recall*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       565\n",
      "           2       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.99       570\n",
      "   macro avg       0.80      0.80      0.80       570\n",
      "weighted avg       0.99      0.99      0.99       570\n",
      "\n",
      "accuracy: 0.9929824561403509\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, preds))\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando a matriz de confusão e, mais uma vez, comparando com o modelo original, foram classificados 3 dos 5 sistemas da classe minoritária corretamente, sendo que agora, foi classificado de forma correta mais um sistema da classe maioritária, restando apenas 2 sistemas sem exoplanetas incorretamente classificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[563   2]\n",
      " [  2   3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em jeito de conclusão sobre este classificador, a otimização permitiu melhorar ligeiramente os resultados, na medida em que o modelo foi capaz de não classificar erradamente tantos registos como sendo da classe minritária como numa fase inicial. Apesar disso, o número de classificações corretas de sistemas com exoplanetas menteve-se, não sendo possível alcançar valores mais altos da métrica de *recall*. Assim, este tipo de classificador dificilmente permitirá obter melhores resultados do que os obtidos para os dados em estudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
