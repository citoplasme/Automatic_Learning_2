{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Aprendizagem Automática II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procura de Exoplanetas no Espaço através da Emissão de Luz de Estrelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np  \n",
    "\n",
    "import matplotlib            \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns        \n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import os\n",
    "\n",
    "from random import randint\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "import sklearn               \n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold, chi2\n",
    "\n",
    "from warnings import simplefilter\n",
    "\n",
    "%matplotlib inline\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pd.read_csv(\"../../../Dados/dados_treino.csv\")\n",
    "teste = pd.read_csv(\"../../../Dados/dados_teste.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo para a análise dos dados é a sua divisão entre *features* e *labels*. Note-se que o conjunto de treino foi ainda divido em dois, sendo 20% do conjunto inicial alocado como conjunto de validação. Esta divisão é efetuada de forma aleatória, permitindo uma análise mais realista do comportamento dos modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "Y = treino['LABEL']\n",
    "X = treino.loc[:, treino.columns != 'LABEL']\n",
    "x_train = X.values\n",
    "\n",
    "# One Hot Encoding\n",
    "y_train = to_categorical(Y.values)\n",
    "y_train = y_train[:, 1:]\n",
    "\n",
    "train, validation, train_target, validation_target = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No que toca ao modelo, após sugestão do docente da unidade curricular, foram definidas 3 camadas *Dense*. As duas primeiras camadas deste modelo possuem 64 neurónios, tendo como função de ativação uma unidade *ReLU*. Por fim, a camada final possui dois neurónios, um por cada classe possível, sendo a função de ativação *softmax*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# 2 Nodos de Saída\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o sumário do modelo, são visíveis as três camadas previamente definidas, bem como o formato dos seus *outputs* e número de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 64)                204736    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 209,026\n",
      "Trainable params: 209,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No que toca ao otimizador do modelo foi utilizado *Adam*, com *learning rate* de 0.001. Além disso, foi utilizado um *checkpoint* em que este monitoriza a *accuracy* do conjunto de validação, armazenando os pesos do modelo no ponto em que esta métrica é máxima. Além disso, é guardado um histórico do treino, permitindo a visualização da evolução das métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5252 samples, validate on 1313 samples\n",
      "Epoch 1/200\n",
      "5252/5252 [==============================] - 1s 270us/step - loss: 3.5718 - accuracy: 0.7666 - val_loss: 3.4670 - val_accuracy: 0.7746\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77456, saving model to best_model.pkl\n",
      "Epoch 2/200\n",
      "5252/5252 [==============================] - 0s 76us/step - loss: 3.5078 - accuracy: 0.7717 - val_loss: 3.4670 - val_accuracy: 0.7746\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.77456\n",
      "Epoch 3/200\n",
      "5252/5252 [==============================] - 0s 75us/step - loss: 3.1993 - accuracy: 0.7915 - val_loss: 3.4842 - val_accuracy: 0.7730\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.77456\n",
      "Epoch 4/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 3.4833 - accuracy: 0.7732 - val_loss: 3.1859 - val_accuracy: 0.7928\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.77456 to 0.79284, saving model to best_model.pkl\n",
      "Epoch 5/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 3.0063 - accuracy: 0.8033 - val_loss: 3.2093 - val_accuracy: 0.7913\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79284\n",
      "Epoch 6/200\n",
      "5252/5252 [==============================] - 0s 79us/step - loss: 2.8990 - accuracy: 0.8111 - val_loss: 2.9165 - val_accuracy: 0.8104\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79284 to 0.81036, saving model to best_model.pkl\n",
      "Epoch 7/200\n",
      "5252/5252 [==============================] - 0s 76us/step - loss: 2.5832 - accuracy: 0.8315 - val_loss: 2.5822 - val_accuracy: 0.8317\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.81036 to 0.83168, saving model to best_model.pkl\n",
      "Epoch 8/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 2.3586 - accuracy: 0.8458 - val_loss: 1.9416 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.83168 to 0.87205, saving model to best_model.pkl\n",
      "Epoch 9/200\n",
      "5252/5252 [==============================] - 0s 83us/step - loss: 2.0007 - accuracy: 0.8692 - val_loss: 1.5402 - val_accuracy: 0.8987\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.87205 to 0.89871, saving model to best_model.pkl\n",
      "Epoch 10/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 1.0069 - accuracy: 0.9330 - val_loss: 0.4868 - val_accuracy: 0.9680\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.89871 to 0.96801, saving model to best_model.pkl\n",
      "Epoch 11/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 1.3521 - accuracy: 0.9111 - val_loss: 1.2763 - val_accuracy: 0.9147\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.96801\n",
      "Epoch 12/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.5094 - accuracy: 0.9661 - val_loss: 0.1991 - val_accuracy: 0.9871\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.96801 to 0.98705, saving model to best_model.pkl\n",
      "Epoch 13/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.5182 - accuracy: 0.9659 - val_loss: 0.9788 - val_accuracy: 0.9345\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.98705\n",
      "Epoch 14/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.4852 - accuracy: 0.9678 - val_loss: 0.4334 - val_accuracy: 0.9718\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.98705\n",
      "Epoch 15/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.3744 - accuracy: 0.9751 - val_loss: 0.1640 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.98705 to 0.98934, saving model to best_model.pkl\n",
      "Epoch 16/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.2538 - accuracy: 0.9832 - val_loss: 0.1640 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.98934\n",
      "Epoch 17/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.2809 - accuracy: 0.9813 - val_loss: 0.5036 - val_accuracy: 0.9673\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.98934\n",
      "Epoch 18/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.5301 - accuracy: 0.9648 - val_loss: 1.1913 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.98934\n",
      "Epoch 19/200\n",
      "5252/5252 [==============================] - 0s 78us/step - loss: 0.7163 - accuracy: 0.9526 - val_loss: 0.4334 - val_accuracy: 0.9718\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.98934\n",
      "Epoch 20/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.4942 - accuracy: 0.9676 - val_loss: 0.2577 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.98934\n",
      "Epoch 21/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.3715 - accuracy: 0.9754 - val_loss: 0.9186 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.98934\n",
      "Epoch 22/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.3390 - accuracy: 0.9775 - val_loss: 0.3514 - val_accuracy: 0.9772\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.98934\n",
      "Epoch 23/200\n",
      "5252/5252 [==============================] - 0s 80us/step - loss: 0.3285 - accuracy: 0.9785 - val_loss: 0.2460 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.98934\n",
      "Epoch 24/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.2060 - accuracy: 0.9865 - val_loss: 0.1757 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.98934\n",
      "Epoch 25/200\n",
      "5252/5252 [==============================] - 0s 80us/step - loss: 0.3988 - accuracy: 0.9739 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.98934 to 0.99086, saving model to best_model.pkl\n",
      "Epoch 26/200\n",
      "5252/5252 [==============================] - 0s 80us/step - loss: 0.2881 - accuracy: 0.9810 - val_loss: 0.1288 - val_accuracy: 0.9916\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.99086 to 0.99162, saving model to best_model.pkl\n",
      "Epoch 27/200\n",
      "5252/5252 [==============================] - 0s 80us/step - loss: 0.1927 - accuracy: 0.9872 - val_loss: 0.1874 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.99162\n",
      "Epoch 28/200\n",
      "5252/5252 [==============================] - 0s 77us/step - loss: 0.2230 - accuracy: 0.9853 - val_loss: 0.1991 - val_accuracy: 0.9871\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.99162\n",
      "Epoch 29/200\n",
      "5252/5252 [==============================] - 0s 75us/step - loss: 0.2401 - accuracy: 0.9842 - val_loss: 0.1640 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.99162\n",
      "Epoch 30/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.1824 - accuracy: 0.9880 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.99162\n",
      "Epoch 31/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.99162\n",
      "Epoch 32/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.99162\n",
      "Epoch 33/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.99162\n",
      "Epoch 34/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.99162\n",
      "Epoch 35/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.99162\n",
      "Epoch 36/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.99162\n",
      "Epoch 37/200\n",
      "5252/5252 [==============================] - 0s 72us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.99162\n",
      "Epoch 38/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.99162\n",
      "Epoch 39/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.99162\n",
      "Epoch 40/200\n",
      "5252/5252 [==============================] - 0s 72us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.99162\n",
      "Epoch 41/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.99162\n",
      "Epoch 42/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.99162\n",
      "Epoch 43/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.99162\n",
      "Epoch 44/200\n",
      "5252/5252 [==============================] - 0s 73us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.99162\n",
      "Epoch 45/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.99162\n",
      "Epoch 46/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.99162\n",
      "Epoch 47/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.99162\n",
      "Epoch 48/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.99162\n",
      "Epoch 49/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.99162\n",
      "Epoch 50/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.99162\n",
      "Epoch 51/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.99162\n",
      "Epoch 52/200\n",
      "5252/5252 [==============================] - 0s 78us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.99162\n",
      "Epoch 53/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.99162\n",
      "Epoch 54/200\n",
      "5252/5252 [==============================] - 0s 77us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.99162\n",
      "Epoch 55/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.99162\n",
      "Epoch 56/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.99162\n",
      "Epoch 57/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.99162\n",
      "Epoch 58/200\n",
      "5252/5252 [==============================] - 0s 75us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.99162\n",
      "Epoch 59/200\n",
      "5252/5252 [==============================] - 0s 75us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.99162\n",
      "Epoch 60/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.99162\n",
      "Epoch 61/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.99162\n",
      "Epoch 62/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.99162\n",
      "Epoch 63/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.99162\n",
      "Epoch 64/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.99162\n",
      "Epoch 65/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.99162\n",
      "Epoch 66/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.99162\n",
      "Epoch 67/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.99162\n",
      "Epoch 68/200\n",
      "5252/5252 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.99162\n",
      "Epoch 69/200\n",
      "5252/5252 [==============================] - 0s 75us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.99162\n",
      "Epoch 70/200\n",
      "5252/5252 [==============================] - 0s 80us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.99162\n",
      "Epoch 71/200\n",
      "5252/5252 [==============================] - 0s 83us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.99162\n",
      "Epoch 72/200\n",
      "5252/5252 [==============================] - 0s 83us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.99162\n",
      "Epoch 73/200\n",
      "5252/5252 [==============================] - 0s 83us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.99162\n",
      "Epoch 74/200\n",
      "5252/5252 [==============================] - 0s 83us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.99162\n",
      "Epoch 75/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.99162\n",
      "Epoch 76/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.99162\n",
      "Epoch 77/200\n",
      "5252/5252 [==============================] - 0s 83us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.99162\n",
      "Epoch 78/200\n",
      "5252/5252 [==============================] - 0s 85us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.99162\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5252/5252 [==============================] - 0s 78us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.99162\n",
      "Epoch 80/200\n",
      "5252/5252 [==============================] - 0s 79us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.99162\n",
      "Epoch 81/200\n",
      "5252/5252 [==============================] - 0s 77us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.99162\n",
      "Epoch 82/200\n",
      "5252/5252 [==============================] - 0s 77us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.99162\n",
      "Epoch 83/200\n",
      "5252/5252 [==============================] - 0s 77us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.99162\n",
      "Epoch 84/200\n",
      "5252/5252 [==============================] - 0s 77us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.99162\n",
      "Epoch 85/200\n",
      "5252/5252 [==============================] - 0s 80us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.99162\n",
      "Epoch 86/200\n",
      "5252/5252 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.99162\n",
      "Epoch 87/200\n",
      "5252/5252 [==============================] - 0s 94us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.99162\n",
      "Epoch 88/200\n",
      "5252/5252 [==============================] - 0s 90us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.99162\n",
      "Epoch 89/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.99162\n",
      "Epoch 90/200\n",
      "5252/5252 [==============================] - 0s 85us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.99162\n",
      "Epoch 91/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.99162\n",
      "Epoch 92/200\n",
      "5252/5252 [==============================] - 0s 90us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.99162\n",
      "Epoch 93/200\n",
      "5252/5252 [==============================] - 0s 92us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.99162\n",
      "Epoch 94/200\n",
      "5252/5252 [==============================] - 0s 92us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.99162\n",
      "Epoch 95/200\n",
      "5252/5252 [==============================] - 0s 94us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.99162\n",
      "Epoch 96/200\n",
      "5252/5252 [==============================] - 0s 92us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.99162\n",
      "Epoch 97/200\n",
      "5252/5252 [==============================] - 1s 99us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.99162\n",
      "Epoch 98/200\n",
      "5252/5252 [==============================] - 1s 97us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.99162\n",
      "Epoch 99/200\n",
      "5252/5252 [==============================] - 1s 97us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.99162\n",
      "Epoch 100/200\n",
      "5252/5252 [==============================] - 1s 95us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.99162\n",
      "Epoch 101/200\n",
      "5252/5252 [==============================] - 1s 101us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.99162\n",
      "Epoch 102/200\n",
      "5252/5252 [==============================] - 1s 101us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.99162\n",
      "Epoch 103/200\n",
      "5252/5252 [==============================] - 0s 90us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.99162\n",
      "Epoch 104/200\n",
      "5252/5252 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.99162\n",
      "Epoch 105/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.99162\n",
      "Epoch 106/200\n",
      "5252/5252 [==============================] - 0s 85us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.99162\n",
      "Epoch 107/200\n",
      "5252/5252 [==============================] - 0s 91us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.99162\n",
      "Epoch 108/200\n",
      "5252/5252 [==============================] - 0s 88us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.99162\n",
      "Epoch 109/200\n",
      "5252/5252 [==============================] - 0s 85us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.99162\n",
      "Epoch 110/200\n",
      "5252/5252 [==============================] - 0s 85us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.99162\n",
      "Epoch 111/200\n",
      "5252/5252 [==============================] - 0s 90us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.99162\n",
      "Epoch 112/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.99162\n",
      "Epoch 113/200\n",
      "5252/5252 [==============================] - 0s 93us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.99162\n",
      "Epoch 114/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.99162\n",
      "Epoch 115/200\n",
      "5252/5252 [==============================] - 0s 89us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.99162\n",
      "Epoch 116/200\n",
      "5252/5252 [==============================] - 0s 91us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.99162\n",
      "Epoch 117/200\n",
      "5252/5252 [==============================] - 0s 92us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.99162\n",
      "Epoch 118/200\n",
      "5252/5252 [==============================] - 0s 92us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.99162\n",
      "Epoch 119/200\n",
      "5252/5252 [==============================] - 0s 90us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.99162\n",
      "Epoch 120/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.99162\n",
      "Epoch 121/200\n",
      "5252/5252 [==============================] - 0s 92us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.99162\n",
      "Epoch 122/200\n",
      "5252/5252 [==============================] - 0s 92us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.99162\n",
      "Epoch 123/200\n",
      "5252/5252 [==============================] - 0s 90us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.99162\n",
      "Epoch 124/200\n",
      "5252/5252 [==============================] - 0s 92us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.99162\n",
      "Epoch 125/200\n",
      "5252/5252 [==============================] - 0s 85us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.99162\n",
      "Epoch 126/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.99162\n",
      "Epoch 127/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.99162\n",
      "Epoch 128/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.99162\n",
      "Epoch 129/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.99162\n",
      "Epoch 130/200\n",
      "5252/5252 [==============================] - 0s 83us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.99162\n",
      "Epoch 131/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.99162\n",
      "Epoch 132/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.99162\n",
      "Epoch 133/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.99162\n",
      "Epoch 134/200\n",
      "5252/5252 [==============================] - 0s 81us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.99162\n",
      "Epoch 135/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.99162\n",
      "Epoch 136/200\n",
      "5252/5252 [==============================] - 0s 90us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.99162\n",
      "Epoch 137/200\n",
      "5252/5252 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.99162\n",
      "Epoch 138/200\n",
      "5252/5252 [==============================] - 0s 88us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.99162\n",
      "Epoch 139/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.99162\n",
      "Epoch 140/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.99162\n",
      "Epoch 141/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.99162\n",
      "Epoch 142/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.99162\n",
      "Epoch 143/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.99162\n",
      "Epoch 144/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.99162\n",
      "Epoch 145/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.99162\n",
      "Epoch 146/200\n",
      "5252/5252 [==============================] - 1s 101us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.99162\n",
      "Epoch 147/200\n",
      "5252/5252 [==============================] - 1s 103us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.99162\n",
      "Epoch 148/200\n",
      "5252/5252 [==============================] - 0s 92us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.99162\n",
      "Epoch 149/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.99162\n",
      "Epoch 150/200\n",
      "5252/5252 [==============================] - 0s 82us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.99162\n",
      "Epoch 151/200\n",
      "5252/5252 [==============================] - 0s 88us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.99162\n",
      "Epoch 152/200\n",
      "5252/5252 [==============================] - 0s 89us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.99162\n",
      "Epoch 153/200\n",
      "5252/5252 [==============================] - 0s 88us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.99162\n",
      "Epoch 154/200\n",
      "5252/5252 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.99162\n",
      "Epoch 155/200\n",
      "5252/5252 [==============================] - 0s 83us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.99162\n",
      "Epoch 156/200\n",
      "5252/5252 [==============================] - 0s 88us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.99162\n",
      "Epoch 157/200\n",
      "5252/5252 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.99162\n",
      "Epoch 158/200\n",
      "5252/5252 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.99162\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5252/5252 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.99162\n",
      "Epoch 160/200\n",
      "5252/5252 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.99162\n",
      "Epoch 161/200\n",
      "5252/5252 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.99162\n",
      "Epoch 162/200\n",
      "5252/5252 [==============================] - 0s 94us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.99162\n",
      "Epoch 163/200\n",
      "5252/5252 [==============================] - 1s 98us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.99162\n",
      "Epoch 164/200\n",
      "5252/5252 [==============================] - 1s 97us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.99162\n",
      "Epoch 165/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.99162\n",
      "Epoch 166/200\n",
      "5252/5252 [==============================] - 1s 99us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.99162\n",
      "Epoch 167/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.99162\n",
      "Epoch 168/200\n",
      "5252/5252 [==============================] - 1s 99us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.99162\n",
      "Epoch 169/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.99162\n",
      "Epoch 170/200\n",
      "5252/5252 [==============================] - 1s 97us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.99162\n",
      "Epoch 171/200\n",
      "5252/5252 [==============================] - 1s 99us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.99162\n",
      "Epoch 172/200\n",
      "5252/5252 [==============================] - 0s 89us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.99162\n",
      "Epoch 173/200\n",
      "5252/5252 [==============================] - 0s 89us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.99162\n",
      "Epoch 174/200\n",
      "5252/5252 [==============================] - 0s 91us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.99162\n",
      "Epoch 175/200\n",
      "5252/5252 [==============================] - 0s 91us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.99162\n",
      "Epoch 176/200\n",
      "5252/5252 [==============================] - 0s 95us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.99162\n",
      "Epoch 177/200\n",
      "5252/5252 [==============================] - 1s 99us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.99162\n",
      "Epoch 178/200\n",
      "5252/5252 [==============================] - 1s 98us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.99162\n",
      "Epoch 179/200\n",
      "5252/5252 [==============================] - 0s 94us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.99162\n",
      "Epoch 180/200\n",
      "5252/5252 [==============================] - 1s 97us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.99162\n",
      "Epoch 181/200\n",
      "5252/5252 [==============================] - 0s 94us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.99162\n",
      "Epoch 182/200\n",
      "5252/5252 [==============================] - 1s 98us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.99162\n",
      "Epoch 183/200\n",
      "5252/5252 [==============================] - 1s 95us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.99162\n",
      "Epoch 184/200\n",
      "5252/5252 [==============================] - 1s 103us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.99162\n",
      "Epoch 185/200\n",
      "5252/5252 [==============================] - 1s 97us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.99162\n",
      "Epoch 186/200\n",
      "5252/5252 [==============================] - 1s 97us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.99162\n",
      "Epoch 187/200\n",
      "5252/5252 [==============================] - 1s 101us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.99162\n",
      "Epoch 188/200\n",
      "5252/5252 [==============================] - 1s 102us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.99162\n",
      "Epoch 189/200\n",
      "5252/5252 [==============================] - 1s 103us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.99162\n",
      "Epoch 190/200\n",
      "5252/5252 [==============================] - 1s 103us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.99162\n",
      "Epoch 191/200\n",
      "5252/5252 [==============================] - 1s 102us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.99162\n",
      "Epoch 192/200\n",
      "5252/5252 [==============================] - 1s 100us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.99162\n",
      "Epoch 193/200\n",
      "5252/5252 [==============================] - 1s 97us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.99162\n",
      "Epoch 194/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.99162\n",
      "Epoch 195/200\n",
      "5252/5252 [==============================] - 1s 96us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.99162\n",
      "Epoch 196/200\n",
      "5252/5252 [==============================] - 0s 93us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.99162\n",
      "Epoch 197/200\n",
      "5252/5252 [==============================] - 0s 89us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.99162\n",
      "Epoch 198/200\n",
      "5252/5252 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.99162\n",
      "Epoch 199/200\n",
      "5252/5252 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.99162\n",
      "Epoch 200/200\n",
      "5252/5252 [==============================] - 0s 86us/step - loss: 0.1728 - accuracy: 0.9888 - val_loss: 0.1406 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.99162\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "adam = Adam(lr=0.001)\n",
    "chk = ModelCheckpoint('best_model.pkl', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history = model.fit(train, train_target, epochs=200, batch_size=128, callbacks=[chk], validation_data=(validation,validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo a visualizar a evolução das métricas ao longo do tempo, foi definida uma função que recebe a variável de histórico do treino, o nome da métrica no conjunto de treino e no de validação. Tendo estes valores, a função devolve a representação gráfica da evolução das métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(train_history,train,validation):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No que toca às métricas de *accuracy*, é visível que são bastante altas, como seria de esperar pelo enorme número de registos de sistemas sem exoplanetas. Come se pode ver ainda, a curva apresenta um comportamento normal, mostrando que aparentemente o modelo aprendeu corretamente as caraterísticas de ambas as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAHsCAYAAAAQMCHUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeZRkeV3n/feNPXKvrat3mma5Io1AA0IzIOrgwqbMo45HeBTxQUFH0YdRR5/jkRkfxm10Rh3HbRhHGAYHmbEfAUXUmVGWZlEELBr6QnfT9F7VteQaGeu9zx83IjKyKrMqIysj40bW+3UOpzIibkT88ld9+nz6y/d+f0GSJEiSJEkaXm7cC5AkSZImlWFakiRJ2iXDtCRJkrRLhmlJkiRplwzTkiRJ0i4ZpiVJkqRdKox7AZJ0pQjD8DeAr+k+/ErgS8B69/FtURStb/nGCz/nW4AXR1H0xiG++18CR6Mo+uHznr8P+HbgYeC/R1H0/It8xuOBX4mi6Nt2+r2SdNAZpiVpnwyG326IfXUURX+3i895D/CevVsZRFH0MLBtkO56HBDu5fdK0qQzTEtSRoRh2AD+BHg68Grgq4DXAyXgMPCLURT9dhiG3wt8exRFLw/D8K+BjwL/CLgR+CvgB6Ioiof87puAz0ZRNBOG4VcA/wmoAAHwVuB3u39eF4bhB6Io+qYwDF8JvJm0ZXAFeFMURZ/oVsFvA64F/gF4NvDDURT9Zfe73gqciKLo14ffJUnKFnumJSk7SsB7oygKgbuA7wdeGkXRM4HvBH55m/c9Afha0vD9EuBF21z3nWEYfnrwf6SB93w/0V3Hs4CXkramJMDrgHu6QforgN8Bvi2KoqcDPwv8SRiGc93PeBzwzCiKXg38dvd3IQzDWeBbgLftaEckKeOsTEtStnwIIIqi1TAMXw68LAzDJwHPAGa2ec97u5Xo5TAM7yatYm/lXdv0TJ/vduDtYRh+NWml+41RFMVhuKnD4+uB/xlF0b3d9f6vMAxPAc/qvv6xKIra3Z//AHhzGIbHSPuz3xdF0eI2a5SkiWJlWpKyZRUgDMPrgU+TVng/DPzMRd4zeONiQtqasWtRFL0PeBLwR8AzgRPd9QzKd79rUA4odn9eHfi8ReDdwP8JfB9pRVuSDgTDtCRl07OBx4C3AH8BvBwgDMP8qL84DMN3At8ZRdF/A34IWCZtJWmzEZb/J/BNYRje3H3P1wM3AB/f5mP/A/BGIBdF0SdGuHxJ2leGaUnKpr8AHgQi4POkNxc+BjxxH777/wVeHYbhZ0jD8e3AB4HPAfUwDD/RXdMPAX8chuFngV8EXhFF0dJWHxhF0WeAc1iVlnTABEly/v9LJ0nS3grD8AnAXwNhFEW1MS9HkvaMlWlJ0kiFYfhzwEeAHzFISzporExLkiRJu2RlWpIkSdolw7QkSZK0S4ZpSZIkaZcm+gTEOI6TTmf/e77z+YBxfO+kcr+G554Nx/0anns2HPdreO7ZcNyv4e3nnhWL+dPAsa1em+gw3ekkLC7u/43hCwtTY/neSeV+Dc89G477NTz3bDju1/Dcs+G4X8Pbzz07dmz2y9u9NrIwHYbhc4FfiqLoa897/hXAz5KepPX7URT9xzAMq8A7gKuAFeA1URQ9Nqq1SZIkSXthJD3TYRj+JPBWoHLe80Xg3wHfCLwI+IEwDK8GfhA4EUXRC4G3Az8zinVJkiRJe2lUNyDeA/wfWzz/FODuKIrORVHUBD4MvBB4AfDn3WveD7x4ROuSJEmS9sxI2jyiKPofYRjetMVLc8DSwOMVYP6853vPXVI+H7CwMHUZK92dfD43lu+dVO7X8Nyz4bhfw3PPhuN+Dc89G477Nbys7Nl+34C4DMwOPJ4FFs97vvfcJXkD4mRwv4bnng3H/RqeezYc92t47tlw3K/h7fMNiNu+tt9h+vPAk8IwPAysAl8D/ArwOOClwCeAlwAf2ud1SZIkSUPblzAdhuGrgJkoin4vDMM3AR8g7df+/SiKHgrD8LeBt4Vh+GGgCbxqP9YlSZIkXY6Rhekoiu4Dntf9+Z0Dz78XeO9519aA7xjVWiRJkqRR8DhxSZIkaZcM05IkSdIuGaYlSZKkXTJMS5IkSbtkmJYkSZJ2yTAtSZIk7ZJhWpIkSdolw7QkSZK0S4ZpjV6SjHsFkiRJI2GY1mgkCcUHPsTc+15D4ZeupXDyU+NekSRJ0p4b2XHiunLlz93N3AfeQOHMXcTVo5AvMvXJ32T5pf/pku8N6ueY/shbyK89sg8rza58Icd8Ox73MiaG+zU892w47tfw3LPhuF+XlgR51m77aTpHv3LcS9nEMK291Vxj7v3fT65+luV//O9oPOlbOHzityh95N+SX7yXzsLN2741t3w/8+/7HvJL99O+6mn7uOgMinMEHf+lumPu1/Dcs+G4X8Nzz4bjfl1arkAQt8e9igsYpg+yuEPQXu8/TIrTEASj+74kYfav/wX5xXtY+pY/pHX9P0qX8ezvJ/ex36T66d9j9Wt/ccu3Fk59hvn3fS/ETZa+9Z20rn3e6NY5ARYWplhcrI17GRPD/RqeezYc92t47tlw3K/JZZg+wBb++8spPnai/7h26z9j7bafHtn3Ve58B5Uv/n+sPfcn+0EagJmrqIffTuWud7P21T9OMnV00/vyZ+5i4fbvIK4eYekV76Zz6In919qdmGbnyruBsdhoU2t2xr2MieF+Dc89G477NTz3bDju16XlAqgU8+NexgUM0wdV3KZw+k6aN76I5vVfQ/Uffp/86c+N7OvyZz7PzIfeTOPGr6P2rB++4PX1Z76eyufeSfXEf6b23J/oPx80V5n789cTl2ZY/LbbiaevBuDBxXX+6FMP857PPsqa/3KRJOmKFwD/5lufyoueeGTcS9nEMH1A5dZPEyQxjcd/E/VbvofSgx8iVz87su+rfvqtJPkiKy/+dQguHBLTWbiZ5uO/keqJt7H+Vf8XSfUwJAkz//snyS99iaVvfRfx9NV04oSf+0DE+z93ilwu4MVPPkp41czI1p1V1WqJ9fXmuJcxMdyv4blnw3G/hueeDcf9urRCPsfTr5sb9zIuYJg+oHJrpwCIp65K/6wcprh472i+rLlG5e73Un/St6QheRu1W/8ZC1/6Sw6//bk0vuI7iCuHqdz9Hlaf91O0rrsNgA/ec4Y/+9wpvuMZ1/La597AsZnyaNaccfbODcf9Gp57Nhz3a3ju2XDcr8nlnOlJ1Frn8Ntvo/jAB7e9JFfrhunp4+mf1cME66OpTJfveR9Bu0b9Kd950evuaDyeb278PB8pfw2Vz7+L6b/7NRo3vZj1W3+of81/+dsHuXa+wpu+7glXbJCWJEmTwzA9gXL1c+RXHqBw9gvbX7P2KADxVBqmk8phcq1V6DT2fD2Vz/8Rq9M38Y1/0malvv3Imo986SxfSG7ku8+8hn910x+y/LX/hpUX/0a/LeQzDy1x4pFlXv2s6yjkRjh1RJIkaY8YpidR3O2pate3vWSjzeNY+mclbb/I7XF1Or94L6VHPs4Hp76Bx9Za3HtmbdtrP3bfOZ594wLf85zr+YM76/z7pdtIyhu9T//lbx9kvlLgFbdcvadrlCRJGhXD9AQKOq30z4uG6ZPE1SOQLwJpmwekJwzupfJd7yYJcvzX+vMBeGBxfcvrTq40uPdMjdtuOsQPv/DxvOKpx/mPH72fX/yrL7LWbHPf2RofvOcM3/6Ma6lmcOyNJEnSVrwBcRLF3TB9kZaNXO1Uv8UD6N8YmFs/y54Nmos7VO56N/XrX8TH7qkACQ8ubh3wP35fGuKf+7hDBEHA//ONT2a2UuAPP/kQH7n3LNcfqlIq5Pinz7x2r1YnSZI0clamJ1DQ6bZ5XCxMr50knr6q/7jf5rGH4/GKD3yQ/NqjfPHqb6ETpwerPLhNZfqj953jyHSJJx2bBqCQC/i/v/YJvPW7nkGlmOPv7l/kZV95nMNTpT1bnyRJ0qhZmZ5E8Q7aPGonaR55Sv/xvbUKh4Fgh2E6WD9DrrFEZ+Hmba8pf/mvSApT/A3PAh7kiUent6xMd+KET9x/jhfefJjgvOPMv+raOd7x3c/iL+46lbkh7JIkSZdiZXoC9SrT27Z5xB1ytcf6Y/GSJOGNf/ogALXFkzv6jpk7/jVzf/q9F72m+OBHaV37HD5zss41c2Weft3clpXpEw8tsVxv87ybtp5BXS7keMUtVzNXKe5obZIkSVlhmJ5EvTC9TWU6WD9DkMT9No9Tq00eXm2zmExzx+fuZrHWuuRX5M/cRe4iNysGtcconPsCzeuez2cfWeGWa+a4br7CUv3C8Xgfvvs0AfDcxy3s8BeUJEmaDIbpCRR02zy265nO19Lqc68yfeejK+nj6hFKzUV+7PbPUmte5DbEJCG/eA9Be+v+Z4DSQx8F4NSh5/DoSoNbrpnlhoUqAA8ubX7fh+8+zVccn+GQ/dCSJOmAMUxPoktUps8/SvzOR5Yp5AKm54/x7KMxnz+5wq//zfZHi+dqJ8m11tLPT+Itryk+dAdxcYZPNm8E4GnXzHF9N0w/cG4jTK822nz6wSWed9OhIX9JSZKk7PMGxAkUXGI0Xq5fmU4PP7nz0RWefNUMVI9wpP0gz7lxgejU6rafnz93z8aDdh2KUxdcU3zoDlrXPpcTJ9cp5AKefNUMcZJO9HhoaSPk/939i3TihOc+zjAtSZIOHivTk6h7aMt2JyDm1rpheuoYnTjh84+ucsvVs8TVQwT1sxybKfPY6vZj9fKLG1XrrVo9cmuPUli8l9Z1z+ezjywTXjVDuZCjWsxzdLq0qTL99w8uUS7keNo1cxd8jiRJ0qQzTE+gIO61eWxTmV47RVw5BPkSXzpbo9bq8NRrZkkqh8mtn+Wq6SJn1pr92dDnyy9uVKaDVu2C14sP3gHA+rW38blHV7jlmtn+a9cvVHhwoDL9yQcWeeYNC5QK/qMmSZIOHhPOJOqPxtu+Mt27+fBzj6Q3Hz716lni6hGCuMm11Q6dBM7Wmlu+f7DNY6vKdPGhO4jL80Q8jno73lR1vn6h2h+Pt1xv8cXH1vjqbUbiSZIkTTrD9AQK+m0e2/dM944S/+yjy8yWC9xwqNo/BfHaUlptPrW6dZguLN5LXJxJv2uLMF166KOsHHsOv3PHAwA89bzK9GOrTeqtDp9+aJkE+OrHG6YlSdLBZJieRP0bEC9dmb7zkRW+8uoZckFAUk1D7dXFNQAeW9kijHca5FYeoH30qel3nBem66fvI7/8ZX7jvmv52/sX+aEX3NSf4gEMjMer8/cPLFHKBzzj+vnL+GUlSZKyyzA9gYKLjcZL4vT0w6mrqLc63HN6jad22zDiSjpR42guneSxVWU6v3gfQRLTPtYN0wM9061OzB+/738AULr5hfzx9z2H1z73xk3vv64bph9aXOfvH1zkqdfMUS7mL+fXlSRJyizD9CQaHI2XbL6JMD39sENn+jh3nVylk6T90kC/zWM+XiKfC7ac6NG7+bB99Jb0iW5lOkkSfvGvvkhh6R7iIM/3vfybuGq2fMH7b1ioAHDXyVWiU6s8y6q0JEk6wAzTE6hXmQYuOAWxf2DL9FX9kw97YTqpHgEg3zjH0enSNmE6HYt3fpvHOz/5EO/57Emec3UJSjMQbP2PzlylyFylwJ997iRxArfeYJiWJEkHl2F6Eg2E6fNbPfJrjwIQTx3ns4+scM1cmSPT6THeSWmWJFdIx+PNlLZs8ygs3kNn+jjJ1NH081t1Pv7lc/zGB+/l6590lKcdzZFscYjLoOsXqjy83KCQC5wvLUmSDjTD9ATqnYAIF56CmKv1KtPHufPR5X5VOr04IK4c7h/ccnqrnulz99BZeEI/MAftGrf/wyMcmS7xL18SErRqJMXpi67v+vm01eOWa2ap2C8tSZIOMMP0JOpshOnzT0HsnX74aDzPI8sNvuq6zW0WSeUQufpZjs2UOHV+m0eSkF/shul8GoiD9jonHl7m1uvnqRbzBO0dhOlD6U2It9ovLUmSDjjD9ATqnYAIW1em4/ICn3okDdm3nhem4+phgvVzHJsps9bsUGt2Nj6rfpZcY4nOoSdAvkiSK7K2tsKp1Wa/XSNorV2yzaN3E+Kt1y/s/peUJEmaAIVxL0C70LlIm0d3xvSnHlpiupTnicc2V5GTymHyZyOOzaR91KdWG9x0OA3HvZMPOws3p9cWqpxbWgLgadf2wnStP8N6O1//pGPUmh2efaNhWpIkHWxWpifQYM/0Vm0e8fRx/v7BJZ5+3Rz5XLDp9bh6pHsDYjrWbnCiR6E3Fm/hCQAkxSpLK8uUCzme3A3laWX64m0eU6U8//SZ113w3ZIkSQeNYXoCDVajg/aFbR710lG+dKbGM667sGc5rhwiaCxybCq9MfCxgZsQ84v3kOTLxLPXA2llem1tla88PkMhn/6jspM2D0mSpCuFYXoSdVok+bSyfP6R4rnaaR7upBM8troBMKkcJkhiri6nIfzUwJHi+eX76czdALk0aMf5Kq3GWr/FA9I2j6RgmJYkSQLD9EQK4hZJaSZ9MNjm0WkSxE3urxUp5QOecnz2gvfG1fQUxKn2EjPl/KbKdDr2bqb/uEaZStLYmBWdJDtq85AkSbpSGKYnUadJXEqD8mBlOmitAXDvMtxyzRylwoV/vb0jxXuzpjeNx2uvkxQq/YdL7QLVoLFRme7UCZLYNg9JkqQuw/QkilskvTA90DMdtGoA3LcS8IxtZjz3jhTPrZ/hqpnS5sp0uw4DYfpss8BcvtU/QbH3+VamJUmSUobpCRR0BsP0hZXp1aRywXzpnl5lOtetTA9O8wja9X5lOkkSHmvkmC+0L/h8w7QkSVLKMD2J4mY/TDM42aMbdteDyqabBje9tXIovXb9LFfNlDiz1qQTJ+lz7Xr/5MNHVxqca5WYDi78fNs8JEmSUobpLIvbVP/+t6C1vunpoNPcpjKdtmEcOXSIqVJ+688sVkkKVXL19BTETgJna91Wj85GZfrEw8usU6LChW0kVqYlSZJShukMKzx2gpmP/jylBz+86fmg0yIpVEhyxU0zp7/40EkAHn/1sYt+blw53G/zADjV7Zse7Jk+8cgKrVyZwhY3OBqmJUmSUobpDOsF5eC8Uw6JmyS5YlpF7r525yPLvOsTXwDg5U+/+aKfG1cOEayf7R8pfnp143t6lekHF9cpV2bSNcSd9HXDtCRJ0iaG6Szr9NovNp9yGHRaLLdydIISnWad+87U+NE//izHSunNglMzW/dL9yTFaYL2Old1w/Sp1WY6Q7rT2OiZXm5QrHRDczew2zMtSZK0mWE6w4JOK/3zgsp0iz++8zQn6wF/cef9fOfb/o58LuDVT0tvLrxk5bhYIWivc2iqRD4gnejRbefoVaZPrjSoVGe635/2bNszLUmStFlh3AvQRfTaPAaPDE8SgrhFIy5QrFS5ZabEq6+7npffcpxD934sveQSleOkUCW3dpJ8LuDIdIlTq82NwF6osNpos9JoU53aCNMJEDRt85AkSRpkmM6wIE4r05uODI/T1o8WBYrlKW6az/HGF6U90kG0RpIvQ+7if61JoUrQnRBy1WyZUyuNfphOChVOrqQhfnq6G6a7FelemwfF6uX/cpIkSQeAbR5Z1u2ZHpzY0Wv9aFIgyZc3v9aq7aifOSlU+wH92rkKDy/V+48Hw/RMt/d6sM0jKUxB4D82kiRJYJjOtGCLME23Wt2iQFwoX3AC4k5aMJJCtd86cv2hKo8s1+k008Cc5Cs82g3T87O9WdbdMN2u2eIhSZI0wDCdZVu0efQCdosC5CsXnIC4o7BbqPTbPG5cqBIncGZpqftalZPLdfIBzM3Odz93o83DSR6SJEkbDNMZ1q9Mtwcq051eZTpPUqhccALiTts8grgJcZvrF9LpHY8tLndfS9s8js2UyZW6nzXY5mFlWpIkqc8wnWVb9Ux3b0BsJgW4jDYPSEfu3Xgo/fnc8kr3tbTN4/hsedN1/c8vGaYlSZJ6DNMZ1qtMb5rm0X2uSZGgsLs2j6Q3jaO9zkK1yHQpz+JKN0znKzy63ODqucEw3atM2+YhSZI0yDCdZd2e6c2V6Y0bEIPi+W0e6zuf5kEakoMg4MZDVZZX0zAd58ucWk0r070ReBs907Z5SJIkDTJMZ9iW0zwGbkAMCtXzRuMN2ebRvQnxhoUqq2urAJxr5Wl1Eo7PVrapTBumJUmSegzTWda/AXGg+hxvzJnOFStpC0iSpK/teJrH5pB8/aEq9fX0QJZT6wEAV8+lh78kuZJtHpIkSdswTGdY/wTEzhbTPJI8uWKVgCRtB4k76bHfO2rzSCd49ELyjQtVyqTB/dFaGqaPz5bTa4tVp3lIkiRtw+PEMyzYqjI90OaRK5Y3Xu+eSjjcNI9uZXqhwlnSkP5Q2h7N1b0wXaikPdOdFkGnkZ6AKEmSJMDKdLZtEaZ7NyUm+Y0bBOk0CFppm8aw0zwAbjxUpRI06QQFHllpUy3mmKuk/52VFKbSGxXbtR1/viRJ0pXCynSG9WZKbxp/1xuXly+S5NO/vqBd77eEDDvNA2ChWmQ236IZlDnZnTEdBGm7B4Vq+vn9sG5lWpIkqccwnWXd/ujNlelutTpfgkIaeINOo3/NUDcgtrqHsQQBR8oxjXaJR1caXD1b6V+aFKsErVp/PJ6VaUmSpA22eWTYVqPxgl7AzhfTVg84r3I8RM90ZyOkHyp2qMVFHl2uc3yuPHBtt81jiM+XJEm6Uhims2ywzaM7/q5/kEuh1J/KsblneohpHt050wDzhTZrcZGztVZ/kkd6bTrNwzYPSZKkCxmmM6xfmU7igdMQB9o8BirTDNOGkSuSBPn+DYgAs/k2dYrAxiSP9POq3cq0bR6SJEnnM0xnWbelAwZaPbrP5QrlgXnRw7V5EAQkhWr/BkSA6VyLOiWge2BLV280nm0ekiRJFzJMZ1h/mgdAu7HpuVyh1O+ZpjNkmIbulI6NMF0NWtSTNEwfH7wB0Z5pSZKkbRmms6yzEab7Ez06TWICCoUC9CvTjYE2jOqOPrrXvtFTSBq0c2k4v2qmtHFhsTcar/f59kxLkiT1GKYzLOi0SHLdWdKdXmW6RZsCpUKeJN8N093KdBLkIF/Z9vMGnd/mEbTr5EpVDlWLVIr5zdd1GgTNlfSxYVqSJKnPMJ1lnSZJabb780bPdIsC5UKOpNBt82in0zyS4jT0Dlu5hKRQgdbmMD0/M8NXP27hvOvSSndu/TRJrgT5EpIkSUoZpjMsiJskpbn0524VOYibtChQyucGKtO9ML3zqvEFlelOnfDaY7zlZU/ZfF33M4PaGavSkiRJ5xnJCYhhGOaA3wKeDjSA10VRdPfA6/8C+C5gGfjlKIreF4bhYeALwGe7l90eRdGvj2J9E6PTJC7NkGfzNI8WBUqFHBQGD22pDXVzYFKokquf3XiiXd+YW33eddCtTHvzoSRJ0iajOk78lUAliqLbwjB8HvCrwLcChGH4NOBVwHO7194RhuH/Am4F/jCKoh8Z0ZomTtBp9ds8ejcgBp0mjSRt8yBXSHuqO42hwzTFKsHqxgmIgWFakiRpaKNq83gB8OcAURR9DHj2wGtPAf46iqJ6FEV14IvAVwHPAm4Nw/BvwjB8dxiG14xobZMhSTa1efR7puMWzW6bB0CSL/fnTO+6zaPTIkg6/ekgm/TCdO20bR6SJEnnGVVleg5YGnjcCcOwEEVRGzgB/HQYhrNACXg+8HvAXcAnoyj6qzAMXw38e+DbL/Yl+XzAwsL+B7x8Pjf67+2OxSvOHgJgugxTC1Pkgg7NpMDcTJmFhSmCYpVyvkMQ12H62I7XlZuaJddppNc3lgGozMxSOu/9waH0+3ONRZia29XvvS/7dcC4Z8Nxv4bnng3H/RqeezYc92t4WdmzUYXpZWB24HGuG6SJoujzYRj+JvB+4G7g48Bp4BNArXv97cDPXepLOp2ExcXapS7bcwsLU6P/3uYax4AGVarA+tIS9cUaM/V1WuSh3WFxscbhXIlWbZVCfYX2zA2s7HBd03GRSqvG4mKNoHaOo0Ctlad+3vsL9YBD3Z9bVFjexe+9L/t1wLhnw3G/hueeDcf9Gp57Nhz3a3j7uWfHjs1u+9qo2jw+ArwUoNszfaL3QhiGx4CjURS9APhR4AbSmw7fCnxb97J/DHxyRGubCL2TDuPz2jzizsY0D+iOuNvVNI/KxoSQbj/2xXqmwRnTkiRJ5xtVZfp24BvCMLwDCIDXhmH4JtJK9HuBm8Mw/FugCfxEFEWdMAx/Cvj9MAx/CFgDXjeitU2EoNvm0b8Bsdcz3W5uTPMA6PdMD3kDYqFKELfTfune6YpbhemBAO0NiJIkSZuNJExHURQDbzjv6bsGfn79Fu/5EvB1o1jPRDo/TPeqx50WjaSYTvOgV2GubxzaskO9inPQXifodD97i9MTN1emDdOSJEmDPLQlo4K4BaSV4YRg4ATExuY2j3yZoLFEkHR2Haa5SJsHtnlIkiRtyzCdVb3KdL4E3eozAHFrc5tHoUKufi69dpie6WI3OLfXL97mYWVakiRpW4bpjOr1TJMvpdXnTu/QlhYt8pQHK9PrZ9Kfd9vmcbHKdC5Pkk9PWkxKhmlJkqRBhums6rV55EskhTK0e4e2NNNDWwZ6pnOt1fTnIW9ABAhaA2F6i57p3nekf9rmIUmSNMgwnVH96R25IuQr/ce5TotWMhCmBwPwkCcgQrdnunORyvTAtfZMS5IkbWaYzqpOrzJd7k/sgPTGxBaFfpvHYJ/z7to86hftmR681p5pSZKkzQzTGbXRM13sH8wCkIubNCkOVKbL/ffsJkxzqZ5pNirShmlJkqTNDNNZFQ9M8+gezAKQS9ppZXqgZ7pnuGkeF1amtwvT2OYhSZK0JcN0RgXdNg9yvWkevcp0i+bANA8Kg5Xp3fdMJwSQK130WivTkiRJmxmms6o/Z7rb5tFuQNwhR7ztDYjDTfNI39cfjVeoQBBsealtHpIkSVszTGdUEG8xZ7r7XGvTaLyByvQQo+t6IbwXprdt8WBgNJ5hWpIkaRPDdFb1KtO5EhTKBO1Gv/WjHRQo5LpV5HxvBnQFcrVzM9gAACAASURBVPmdf36+SJIrErTS48QvHqaraRvIRa6RJEm6EhmmM6rfM50vpVXkTqMfsOOB3uZeZXo3VeOkUE2neXTq2x7YApCU50kqC9u2gUiSJF2pCuNegLYWbOqZTqd59Fo/4lyxf93ltGAkhermnult1J75BhpPfPnQny9JknTQGaazqtczneuOxus0+ge5MBCmyfcq07sYW1eo7KxneuoY7aljw3++JEnSAWebR0YFnRZJrghBkJ6A2GkMVKsH2zwuozJdTCvTl+qZliRJ0tYM01nVafZDc++Uw6C5kr422OaRv7ye6WAHPdOSJEnammE6o4K4uRGaezOhW6vp402V6d2fTpgUqtCqX7JnWpIkSVszTGfVpsp0N0w3ltM/81v1TF/eDYi2eUiSJA3PMJ1RQdzqV6B74+9y3TaPXmtH+trlT/OwZ1qSJGl3DNNZ1WmmNyBC/2CWoJm2eQSFrXqmdzHNo1hNR+7ZMy1JkrQrhumMCjrNCyrTQTNt88gVNnqm2Yc505IkSdqaYTqrtpzm0a1MD96AWJxm/ZbX0Hzc1w/9FUm+QtBaI+g0bPOQJEnaBQ9tyajBnun+NI9uz/SmynQQsPqif72r7+jPmQbDtCRJ0i5Ymc6qTpNmUuDF/+EO7l+JgY0bEHMDNyBejt5YPaDfly1JkqSdM0xnVNBpUo/zLNXb3LfcSZ/rheni3oTpwT5pK9OSJEnDM0xnVdyiHaRTO841026cjTBd2vZtwxisTBumJUmShmeYzqig06QTpCH6bCNIn2ykYbpQ2Ps2D8O0JEnS8AzTWdVp0upWps8288BGZbqwV5Xpoj3TkiRJl8MwnVFBp9lv8zhVTyvTue5ovD0L01amJUmSLothOqviFu3u5MLTvTDdXqOd5CgNnIB4WQzTkiRJl8UwnVFBp0mLbptHPe4fLd6iQKmwN39tmyvT1YtcKUmSpK0YpjMqDdNpZXqx1uqfgtgcUZj2OHFJkqThGaazKm7R7IbppXoLChthupwfQWXaGxAlSZKGZpjOoiQmiFv9ynScQCeXhum0zSPYm68p2jMtSZJ0OQzTWRS3AGiycaNhuxemkwKlvapM5z0BUZIk6XIYpjMo6DQBaCb5/nO9MXktCpT3qGd6U5+0YVqSJGlohXEvQFvopJXpxkBluhkMtnnsUZjO5dMbG5MEAv+7SpIkaViG6QwK4gsr071g3djLyjTd9o4k2bPPkyRJupJYjsyibptHPS4wX0n/e6eRDLR57FHPNKQTPeyXliRJ2h0r0xkU9No8kjyzlQKNdsx6kh4h3kr2sM2DNEwHSWfPPk+SJOlKYpjOok4DgHpSpJjPsVAtUovTv6oWezfNA4BClSRu793nSZIkXUEM0xkUdEfj1ZM8pXyOcjXHWiv9q9rLExChO2u6WwmXJEnScAzTWdTtmW7EeUr5gOlygdWz6V9VJyiQC/bm0BaAzuz1BN1KuCRJkoZjmM6g3pzp9aRAsZC2eax00r+q3rzpvbLy9b8CDvOQJEnaFcN0FvXaPOK0zWOhWmSpXYAA4j0O0xSql75GkiRJW3I0Xgb1K9NxgWI+4FC1yGo7nTndye1xmJYkSdKuGaazqBuma3GOUiHHQrXQP7RlzyvTkiRJ2jXDdAb1K9OdfH80Xp10znRiZVqSJCkzDNNZ1O2ZrnXSaR4LU0UavTCdN0xLkiRlhWE6g7aqTPeOE7fNQ5IkKTsM0xnUC9Nr3WkehwbbPPKlcS5NkiRJAwzTWdRv88hRzOeYrRRpdm9AxJ5pSZKkzDBMZ1CvMr3a7Zku5ALypQpgZVqSJClLDNNZ1A3TbfKUCulfUbE0lb5mmJYkScoMw3QGBXGzW4EOKObTv6JyJT2pMHCahyRJUmYYprOo0yLOpRXoUj4AoFyZBiAplMe2LEmSJG1WGPcCdKGg0yTphuleZXp97mZ+9qHXUJ5/wTiXJkmSpAFWprMobhJ3p3aUumF6YarE2zvfBOWZca5MkiRJAwzTGRR0Wv1jw4vdNo+Favq4XMiPbV2SJEnazDCdRZ0mnfMq04e6Ybo33UOSJEnjZzLLoCBu9o8NL3bDc78y3a1US5IkafwM01m0qTLdbfOYsjItSZKUNSazDAo6LTrB5jaPxx2q8rRrZvmK47PjXJokSZIGOBovizpN2r02j26YnikX+P1XPXOcq5IkSdJ5rExnUBA3L6hMS5IkKXtMalm0qTLtDYeSJElZZZjOoKDTot3twPGGQ0mSpOwyqWVR3KQdpGG6aJuHJElSZpnUMijoNGmyeTSeJEmSsscwnUGb2jysTEuSJGWWSS2L4o3KtG0ekiRJ2WVSy6Cg06RFnnwA+ZxtHpIkSVllmM6ibs+0VWlJkqRsM61lTdwhSDo0k4Jj8SRJkjLOtJY1cQuAJnkr05IkSRlnWsuYoNMEoJ4UHYsnSZKUcYbprOlVphMr05IkSVlnWsuYoNMAoJ4UnDEtSZKUcYVRfGgYhjngt4CnAw3gdVEU3T3w+r8AvgtYBn45iqL3hWF4FHgnUAUeBl4bRVFtFOvLtE5amW7EBYq2eUiSJGXaqEqfrwQqURTdBvwU8Ku9F8IwfBrwKuB5wDcCPxeG4RTws8A7oyh6IfAp4PUjWlumbfRM561MS5IkZdyo0toLgD8HiKLoY8CzB157CvDXURTVoyiqA18EvmrwPcD7gRePaG3Z1u2Zrsd5io7GkyRJyrRRpbU5YGngcScMw15LyQnga8IwnA3D8AjwfGD6vPesAPMjWlum9SrT607zkCRJyryR9EyT9kLPDjzORVHUBoii6PNhGP4mafX5buDjwOmB96x3/1y81Jfk8wELC1N7vPRLy+dzI/veYCX975sWBaYrxbH8fnttlPt1ULlnw3G/hueeDcf9Gp57Nhz3a3hZ2bNRhemPAK8A/igMw+eRVqMBCMPwGHA0iqIXhGE4D/wF8Nnue14K/AHwEuBDl/qSTidhcXH/71FcWJga2fcWl1ZYAFZbAcTj+f322ij366Byz4bjfg3PPRuO+zU892w47tfw9nPPjh2b3fa1UYXp24FvCMPwDiAAXhuG4ZtIK9HvBW4Ow/BvgSbwE1EUdcIwfAvwtjAMv5+0Uv2qEa0t04LmKgArcZlp2zwkSZIybSRhOoqiGHjDeU/fNfDzBZM6oig6CXzzKNYzSYJG2jZ+Np5iwWkekiRJmWZay5jcQJh2NJ4kSVK2mdYyJmgskRBwtlP2OHFJkqSMM61lTNBYIinP0egElAr2TEuSJGWZYTpjco0l4vI8nTixMi1JkpRxprWMCRpLxKU5AHumJUmSMs60ljG55jLtUnr4Y9HReJIkSZlmmM6YoL5Eu5gOBrfNQ5IkKdtMaxkTNJZoF3ttHlamJUmSsswwnTG5xiLNbpi2Mi1JkpRtprUsadcJOg2ahbTNwxsQJUmSss20liFBYxmARsGeaUmSpElgWsuQ3lHi9Xy3Mu2hLZIkSZlmmM6QoJlWput550xLkiRNAtNahuTqiwCs56cB2zwkSZKybkdpLQzD4qgXonQsHkAt17sB0TYPSZKkLNtp6fOTYRj+WhiGt4x0NVe4Xphey80AVqYlSZKyrrDD654BfDPw5jAMjwHvAP5bFEWrI1vZFSjX7ZleC9I2D3umJUmSsm1HaS2Kohh4P/D7wBngR4APhGH4AyNc2xUnqC+RFKZoxHkAirZ5SJIkZdpOe6Z/GYiAfwL8UhRFTwdeCPzgCNd2xQkaS8SVeZqdBIBSwcq0JElSlu00rX0ReGYURT8AfAr61ep/MqqFXYlyjUWS8jytTgzY5iFJkpR1O01rAfCW7s9/GobhdwNEUXTfKBZ1pQqay8SleZrdMO0NiJIkSdm207T2BuCnuz+/DPih0SznyparL22qTNszLUmSlG07DdOdKIrqAFEUtYBkdEu6cgWNJZJuz3QhF5ALDNOSJElZttPReH8ShuGHgE8AtwLvGd2Srlxpm8ccrU5sv7QkSdIE2FGYjqLoLWEYvg8IgbdHUfSZ0S7rChR3yDVXSMrzNJdjWzwkSZImwE5H4z0ReAlpmH5lGIa/O9JVXYGC7oEtac904lg8SZKkCbDTxPb27p8vAB4PHBnNcq5cQX0RoDtnOnaShyRJ0gTYaWKrRVH0C8CDURR9L3B8dEu6MvWOEk9K892eads8JEmSsm7Hc6bDMLwamAnDcBo4PMI1XZGCxhIAcTmd5mFlWpIkKft2mtj+FfBK4B3Al4D3j2xFV6hcPQ3TSTlt83CahyRJUvbtdDTeV0dR9Cvdn68a1WKuZEGzF6bnaHVO2eYhSZI0AXZa/nxpGIb5ka7kCrfR5rFAs22bhyRJ0iTYaWX6GPBwGIZfIj39MImi6PmjW9aVJ9dYIsmVoFCh1YmZr+70r0aSJEnjstPE9vKRrkIE9SWS8jwEgaPxJEmSJsROw/Rrtnju5/ZyIVe6oLlMXJ4DcDSeJEnShNhpmD7Z/TMAbmXnvdbaoVyjW5kGR+NJkiRNiB2F6SiKNh0fHoaho/H2WNBYIq6k47tbjsaTJEmaCDsK02EYPnng4TXAjaNZzpUrV1+kM38TQLdn2jYPSZKkrNtpm8fvkk7xCIB14MdHtqIrVNBcJikvANDqJFamJUmSJsBOE9tLgH8eRdHXAb8H/NXolnQFShKCxjJxeZ4kSWi2Y4oFw7QkSVLW7TSxvQN4bvfnJwNvG81yrkxBa5Ug6ZCU5+nECQk4zUOSJGkC7DRMXxdF0e8ARFH0y6R909ojQWMZSI8Sb3YSANs8JEmSJsCOE1vvJsQwDJ8AeLT4Hto4SnyeZicGcDSeJEnSBNjpDYg/BvxRGIZXAQ8Dbxjdkq48ucYiAEl5nlY3TNvmIUmSlH07LX9+GnhtFEXXAm8BPjO6JV15Nto8rExLkiRNkp0mtv+KNyCOTNBaBSAuTtNq2zMtSZI0KbwBMQOC1nr6Q3FqozLtaDxJkqTM280NiE/EGxD3VNCqAZAUp+yZliRJmiA7vQHxR4F3hWF4nPQGxB8c3ZKuPEG7G6YLUzQ7acuHPdOSJEnZt9PEdiswDTSAo8A7R7aiK1DQqpHky5DL99s87JmWJEnKvp0mttcBLwL+DPhe4M5RLehKFLRrJIUqAKuNNgCz5Z3+nwaSJEkal52G6dNRFD0CzEZR9NfA4dEt6coTtNZJilMALK23AJivGqYlSZKybqdheikMw1cCSRiGrweOjXBNV55WbSNM19PK9HylOM4VSZIkaQeGafP4MvBTpHOmvQFxD6VtHmmYXlxvUS3mKDkaT5IkKfN21EsQRdEK8Knuw38+uuVcmYJWjaSY9kwv1dtWpSVJkiaE5c8MCNrr/cr00nqL+aphWpIkaRIYpjMgaNWgfwNim/mKNx9KkiRNAsN0BgSbbkC0Mi1JkjQpDNMZELRrm0bjWZmWJEmaDIbpDAha6TSPOElYabStTEuSJE0Iw/S4xR2CToOkOMVKvU2cYJiWJEmaEIbpMQvaNQCSwtTAgS22eUiSJE0Cw/SYBa1umC5Osdg/StzKtCRJ0iQwTI9bP0xXWeqG6QUr05IkSRPBMD1mQXsd6LV5WJmWJEmaJIbpMRts81ha7/VMG6YlSZImgWF6zDbfgNgiH8BMOT/mVUmSJGknDNNj1qtM061Mz1WKBEEw3kVJkiRpRwzTY7apzaPeYr7qzYeSJEmTwjA9ZhttHtXuUeL2S0uSJE0Kw/SYBa3uNI9iemiLkzwkSZImh2F6zDbdgLje8vRDSZKkCWKYHrOgVSPJFSFftDItSZI0YQzT49aqkRSnqLc6NNqxlWlJkqQJYpges6BdIylUWVz39ENJkqRJY5ges6C13r/5EAzTkiRJk8QwPWZpZTq9+RCwzUOSJGmCGKbHLGjV0tMPrUxLkiRNHMP0mAWtGkmx2q9ML1iZliRJmhiG6TEL2utpm0fdGxAlSZImzUjKoGEY5oDfAp4ONIDXRVF098DrPw58FxADPx9F0e1hGAbAg8AXu5d9NIqinx7F+rIk6I7GW1pvM1XMU8z73zeSJEmTYlQ9Ba8EKlEU3RaG4fOAXwW+FSAMwwXgjcATgWng08DtwBOAv4+i6BUjWlMmDd6AOF+1xUOSJGmSjKoM+gLgzwGiKPoY8OyB19aAL5MG6WnS6jTAs4DrwjD832EY/lkYhuGI1pYpg5Xp+YotHpIkSZNkVKXQOWBp4HEnDMNCFEXt7uMHgM8BeeAXus89AvxCFEXvDsPwBcA7gOdc7Evy+YCFham9XfkO5PO5vfneJCZor1OenWflwQ5HZstj+X1Gbc/26wring3H/RqeezYc92t47tlw3K/hZWXPRhWml4HZgce5gSD9EuAa4PHdxx8Iw/AjwN8BbYAoij4chuF1YRgGURQl231Jp5OwuFjb+9VfwsLC1N58b3ONY8B6u8jZ1QZXT5fG8vuM2p7t1xXEPRuO+zU892w47tfw3LPhuF/D2889O3ZsdtvXRtXm8RHgpQDdnukTA6+dA9aBRhRFdWARWADeDPxY9z1PB+6/WJA+CIJ2+g9Av83DSR6SJEkTZVSV6duBbwjD8A4gAF4bhuGbgLujKHpPGIYvBj4WhmEMfBj4S+BvgXeEYfgy0gr1945obZkRtNIw3clXWWm0Pf1QkiRpwowkvUVRFANvOO/puwZefzNpJXrQOeBlo1hPVvUq0zVKgDOmJUmSJo1DjceoV5le7ZQBHI0nSZI0YQzTYxS01gFYjruVaUfjSZIkTRTD9Bj12jwW27Z5SJIkTSLD9Bj12jwea+QBODZdGudyJEmSNCTD9Bj1KtMP1XIUcgFHZwzTkiRJk8QwPUa9yvQDawHHZ8vkgmDMK5IkSdIwDNNj1LsB8f7VgGvmK2NejSRJkoZlmB6ndo0kyPPAcodrZsvjXo0kSZKGZJgeo6BVIylOcbrW4po5K9OSJEmTxjA9RkG7RjtfBeDqOSvTkiRJk8YwPUZBq0YrSCvS19ozLUmSNHEM02MUtNapB2lF2sq0JEnS5DFMj1HQrlGjQi6A4zOGaUmSpEljmB6joFVjNS5xdLpEIe9fhSRJ0qQxwY1R0K6x1CnZLy1JkjShDNNjFLTWWWwXudqxeJIkSRPJMD1OrRrnWgWu8eZDSZKkiWSYHqdWjbWkbGVakiRpQhmmxyVJyLVrrFHhWivTkiRJE8kwPS7tOgEJ61amJUmSJpZhekyCdg2AGmWunrUyLUmSNIkM02MStNIwnStNUynmx7waSZIk7YZhekx6YbpcnRnzSiRJkrRbhukx6bV5TE3PjnklkiRJ2i3D9Jgk3cr0zPTcmFciSZKk3TJMj8na6jIAc7OGaUmSpEllmB6T5ZU0TC/Mz495JZIkSdotw/SYrKwsAXB4fmHMK5EkSdJuGabHpL12BoD5w1eNeSWSJEnaLcP0mAS1M9STIrMz9kxLkiRNKsP0mBQa51gM5snl/CuQJEmaVCa5MSk3z7Gc8+ZDSZKkSWaYHpNqe5FawZsPJUmSJplhekxmOks0ioZpSZKkSWaYHpOFZIlW+fC4lyFJkqTLYJgeg/r6GtNBnbhqmJYkSZpkhukxWF08CUAwdWTMK5EkSdLlMEyPwdriKQAKM8fGvBJJkiRdDsP0GDSXHwOgPGeYliRJmmSG6TForaZhujrvUeKSJEmTzDA9BvHaaQBmFq4e80okSZJ0OQzTYxCsn6Wd5ChPO2dakiRpkhmmx6DQOMNSMEeQc/slSZImmWluDMrNRVZy8+NehiRJki6TYXoMqu1F1gq2eEiSJE06w/QYzHaWaBQPjXsZkiRJukyG6X2WJAnzyRKtskeJS5IkTTrD9D5bq9dZCNaIq4ZpSZKkSWeY3mfL59IDW4LpI2NeiSRJki6XYXqf1RZPApCf8ShxSZKkSWeY3meN5bQyXTFMS5IkTTzD9D5rr6ZhujpvmJYkSZp0hul9Fq+dBmDm0PExr0SSJEmXyzC9z3L1swDkvQFRkiRp4hmm91m+fpYlZiBXGPdSJEmSdJkM0/us3DrHSs6jxCVJkg4Cw/Q+q7YWWSvMj3sZkiRJ2gOG6X02Gy/RKHn6oSRJ0kFgmN5HnThhIVmiVT407qVIkiRpDxim99HSeoMFVkmqTvKQJEk6CAzT+2h58TSFICaYOjrupUiSJGkPGKb30friKQAKzpiWJEk6EAzT+6i+nIbp0pxHiUuSJB0Ehul91FpNjxKfmr9qzCuRJEnSXjBM76Pls48CML1wfMwrkSRJ0l4wTO+jtcWTACRT9kxLkiQdBIbpfXKu1qRYP009Pwv58riXI0mSpD1gmN4nJx5Z4WiwRLvqWDxJkqSDwjC9T048vMxVwRKFWfulJUmSDgrD9D458cgy1xRWYNpJHpIkSQeFYXoftOOEOx9Z4SiLxJ5+KEmSdGAYpvfBPY+tQXudSlwjnrIyLUmSdFAYpvfBPzyyzNFgCYDEGxAlSZIODMP0Pjjx8DJPqNYAiKc8SlySJOmgMEzvgxOPLHProQZgmJYkSTpIDNMjdrbW5MHFOl85uw7gDYiSJEkHiGF6xE48vALAzZU1AGJ7piVJkg4Mw/SIfeHUKgFwPLdEXF6AfGncS5IkSdIeMUyP2FK9xXQ5T7F+xrF4kiRJB4xhesRWmx1mSgVy66ftl5YkSTpgCqP40DAMc8BvAU8HGsDroii6e+D1Hwe+C4iBn4+i6PYwDKvAO4CrgBXgNVEUPTaK9e2ntUab6XKe3NopWsefMe7lSJIkaQ+NqjL9SqASRdFtwE8Bv9p7IQzDBeCNwG3ANwK/1n3pB4ETURS9EHg78DMjWtu+6lWmg/XTjsWTJEk6YEYVpl8A/DlAFEUfA5498Noa8GVguvu/+Pz3AO8HXjyite2rtUabI8U2udaakzwkSZIOmJG0eQBzwNLA404YhoUoitrdxw8AnwPywC9s8Z4VYP5SX5LPBywsTO3NioeQz+d2/L21VswNh9KxeJWj11Mew3rHbZj9Uso9G477NTz3bDju1/Dcs+G4X8PLyp6NKkwvA7MDj3MDQfolwDXA47uPPxCG4UfOe88ssHipL+l0EhYXa3uz4iEsLEzt+HuX11scjc8CsMYczTGsd9yG2S+l3LPhuF/Dc8+G434Nzz0bjvs1vP3cs2PHZrd9bVRtHh8BXgoQhuHzgBMDr50D1oFGFEV10tC8MPge0sD9oRGtbV+tNtsc7RbcHY0nSZJ0sIyqMn078A1hGN4BBMBrwzB8E3B3FEXvCcPwxcDHwjCMgQ8Df9n9821hGH4YaAKvGtHa9k2zHdPqJBzph2l7piVJkg6SkYTpKIpi4A3nPX3XwOtvBt583us14DtGsZ5xWW2mnS0L8TkSAuLKkTGvSJIkSXvJQ1tGaLXRAWA+PkdSOQT54phXJEmSpL1kmB6h1UZamZ5pn3XGtCRJ0gFkmB6hXpieahmmJUmSDiLD9AitNtM2j2rzjAe2SJIkHUCG6RFa61ami/UzjsWTJEk6gAzTI7Ta7DBFnXxn3bF4kiRJB5BheoRWG22OBelBjlamJUmSDh7D9AiUv/gnzL/31QSrJ7musAJ4YIskSdJBNKoTEK9opfv/htL9f8PrC5/nXYWvg8TKtCRJ0kFkZXqP3HN6jTu+dBaAoPYYnZlryMVtfjB5F4DTPCRJkg4gw/Qe+c8fv5+f+8AXAMitn6F95Cn8zOF/y/25G0jyZZLq4TGvUJIkSXvNML1HztRanF1r0o4TcuuPkVSPcl/nCD975Nc49x1/Bjk7aiRJkg4aw/QeObvWJAEW1xrkameIp46y2mhTqM7SORKOe3mSJEkaAcP0HjlXawGwuHiWIG4SV4+y2ugwXbIiLUmSdFAZpvdAO05YXE/D9OriowDdMN1mupwf59IkSZI0QobpPbC03iLp/txYOglAq3yYejtmpmxlWpIk6aAyTO+Bs7Vm/+fWyikA1orp9A7DtCRJ0sFlmN4DZ7v90gCsPQbAcn4BgJmSbR6SJEkHlWF6D/Qq08V8QG79NAkBi8wBMG1lWpIk6cAyTO+B3iSPm49MU2qcIakcYrVbrLYyLUmSdHAZpvfAmbUWhVzATYerVFvniKeOsdroAPZMS5IkHWSG6T1wrtbk8FSRI9MlZjvniKtHWGu2AcO0JEnSQWaY3gNnay0OT5U4Ol3iULJEs3KE1UYvTNvmIUmSdFAZpvfA2VqTQ93K9NFgibX8Idaa3TYPT0CUJEk6sAzTe+BsrcXh6RLHKglzwTpL+QVWG22K+YBSwS2WJEk6qEx6lylJkrRnulrkeH4FgHPMs9roWJWWJEk64AzTl2mt2aHZSdLKdLAEwKl4nv+/vXsPj6q+8zj+nsnkwoRAQgig9YJA/eriWkFaWwpKqdYqRXG3Wh/vq1ZtS59tbaUWL6wt3XYttkW7VKm40a3KUrt2pQJiV0VRWbsqq1L9egGpPgZMSALkYm4z+8c5QcSAnUnCmSSf1z+ZOXPOeb7ze37PL5/5zW/OaWhp13ppERERkX5OYbqbOu9+OCyZz5COegCqOgbT0NquK3mIiIiI9HMK091U2xjc/XBYMp+85hoA3m4toaGlQ3c/FBEREennFKa7qbY5mJkuSxYQC8P0my1JGlvbdfdDERERkX5OYbqbOmemy5P5xJtraI4NoqoprplpERERkQFAaa+b6sI106XJAuJNNTQkStnW2EpLe0oz0yIiIiL9nMJ0N21ramVoUYJEPBbMTOeXU7czCNj6AaKIiIhI/6ZlHt1UF96wBSDeXENbUTlpII3CtIiIiEh/pzDdTbVNrQxL5gMQb6ohnRy+67ViLfMQERER6dcUpruptqmNYckCSHUQe6+WePGIXa9pZlpERESkf1OY7qbOmenYe3XE0ikKhlTsek13QBQRERHp3xSmu6G1PUVDSwfDkgXEw2tMFw0dtev1wQWamRYRERHpz5T2uqG2KbjGdFkyn3hTEKbzBldQUphmZ4tu7RS+8AAADqRJREFUJy4iIiLR6Ohop66umvb21qhL6TVbt8ZIp9M9es5EooCysgry8v76DKe0l6HCV+4jz++ltCNFQWsH1yZGUlb0w10z06lkBcOL68MwrWUeIiIisv/V1VVTVJSkuHgUsVgs6nJ6RV5enI6OVI+dL51O09i4g7q6aoYPP+CvPk5hOlPxBCSKSNNBW6qZSxMrqV1fS97ozwKQGlROeXEjm2qhWMs8REREJALt7a39Okj3hlgsRnHxEBoa6jM6TmkvQy2Hz2LQp85he30Ty1/awosPL+GmbbcTq36GdDxBurCU8uIt5MVgUL6WpIuIiEg0FKQzl02bKe11Q21TG/enplJ9yp2kCwaTSo6AWIwjR5YwdnixOrGIiIgMWC0tLSxf/vu/at8VK5azdu2aXq6od2hmuhtqm1oZlB8nPnoKdWetJN68DYBzJx3EuZMOirg6ERERkejU1m5j+fLfM3PmrI/c99RTZ+6HinqHwnQ3bGtspSwZ3Eo8NXQ0qaGjoy1IREREZA8PbtjKAy9t6dFznnbUKGaMH7nPfe666w7efHMTU6d+kkmTPkVzczNXX30dq1Y9yCuv/JmmpiZGjz6MuXPnsWTJbZSXl3PIIaO5++67yM9PUFX1DtOnn8SFF17So7X3NIXpLKXSaZ5/eztHjCyJuhQRERGRnHPBBRfzxhuvc9xxn2Hnzp1861vfpbGxgZKSEn7xi0WkUinOP/8sqqvf/cBxW7dWUVl5L21tbcya9UWF6f7qxXd28G5DK7OPHx51KSIiIiJ7NWP8yI+cRe5thxxyKACFhUXU1dUxb95ckskkzc3NtLe3f2DfMWPGkUgkSCQSFBYWRVFuRhSms/SwV1OYiHP82PKoSxERERHJObFYnHQ6uA50PB5clGHduid5992t/OAHP6auro7HH3/0Qzde6WvXb1CYzkJHKs0fX61h8mHDdC1pERERkS6UlZXR1tZOS0vLrm1HHjmeysolXHbZRRQUFHDggR+jpqY6wiq7T0kwC/+7uY5tja2ceLiWeIiIiIh0pbCwkMrKez6wrbx8OLfffteH9j366GN2PZ44cdKuxw888FDvFdhDdJ3pLKx4qYqiRJypWuIhIiIiMqApTGeoPZVm1YatTBlTzqD8vKjLEREREZEIKUxn6Nm36qltbOUk0xIPERERkYFOYTpDj7xaQ3FBHpMPGxZ1KSIiIiISMf0AMUN/e2AJ4w8upUhLPEREREQGPIXpDH1p/ChKS5PU1zdFXYqIiIiIREzLPEREREQkMrNnX8bmzW+yYsVy1q5d86HXTzvt5H0ev2bNo9TUVLNtWw0LFvykt8rcK4VpEREREYncqafOZMqUEzI+7re/vZfGxkbKy4fz3e9e3QuV7ZuWeYiIiIj0Y4Wv3EfRy0t79JzvHXk2LUd8eZ/7zJ17FWeeeTYTJhzLyy9vYNGimyktLaOhYSfbt9czc+YZnHHG++dYsuQ2ysvLmTnzDG688Uds2rSRj33sIFpbWwHYuPF1brnl56RSaRoadnLllXPYvn07r7/+KvPnX8911/2Q+fPnsXhxJX/60zoWL/4VhYWFDBkylO9//3pee825++67yM9PUFX1DtOnn8SFF17S7bZQmBYRERGRHjdz5ixWrvwDEyYcy4oVf2DixEmMGTOWE06YTk1NNbNnX/aBMN1p3bqnaG1tZfHiSrZs2cJjj/03AJs2bWT27G8zduw4Vq9exYMPPsCcOdcwbtzhXHXVXPLz8wFIp9PceOM/s2jR7VRUjGDZsnu5884lTJ48ha1bq6isvJe2tjZmzfqiwrSIiIiI7FvLEV/+yFnk3nDccZ9h0aKF7NixnRdeeJ4FC27m1lt/yZo1j5JMFtPe3t7lcZs2vcGRR44HYNSoUYwYMRKA4cNHUFl5O4WFhTQ1NTF48OAuj6+vryeZLKaiYgQAxxwzgdtuW8TkyVMYM2YciUSCRCJBYWFRj7xPrZkWERERkR4Xj8f53OdOZMGCnzB16jSWLv0NRx11NNdf/0OmTz+RdDrd5XGHHjqaDRteAKCmpprq6moAFi78KZdccjnXXnsDY8eO23V8PB4nlUrtOr60tJSmpkZqamoAWL/+OQ4++BAAYrGef5+amRYRERGRXjFjxmmcddbpLF16P1VV77BgwY9ZvXolQ4cOJS8vb9d66N1NnTqNF174P7761QsZNeoASktLAfjCF07h6qu/w7Bhw6ioGMGOHdsBOOqoo5k/fx5z5lwDQCwWY86ca7jmmquIx2OUlAxh7tx/YuPG13vlPcb29qmgL2hr60hHcb1nXWc6M2qvzKnNMqP2ypzaLDNqr8ypzTLT0+21ZctmRo06tMfOl4vy8uJ0dKQ+escMddV2FRUlzwKTutpfyzxERERERLKkMC0iIiIikiWFaRERERGRLClMi4iIiPRDffl3cVHJps0UpkVERET6mUSigMbGHQrUGUin0zQ27iCRKMjoOF0aT0RERKSfKSuroK6umoaG+qhL6TWxWKzHPywkEgWUlVVkdkyPViAiIiIikcvLSzB8+AFRl9GrcuXyi1rmISIiIiKSJYVpEREREZEsKUyLiIiIiGSpT99OHKgGNkddhIiIiIj0a4cCXf4ysa+HaRERERGRyGiZh4iIiIhIlhSmRURERESypDAtIiIiIpIlhWkRERERkSwpTIuIiIiIZEm3E8+AmcWBRcAngBbgUnd/PdqqcouZ5QN3AKOBQmA+8DawHHgt3O1X7v4fkRSYo8zseWB7+HQTcBuwEGgHVrv7DVHVlmvM7CLgovBpEXAMcA7wU+CtcPs8d1+z34vLQWZ2HPAv7j7NzMYBlUAaeAn4hrunzGweMIOgv33L3Z+JrOCI7dFexwC3AB0EY/4F7r7VzG4GPgvsDA873d23d33G/m+PNptIF+O9+tj79mivpcCo8KXRwDp3P9vMHgDKgTag2d1PiabaaO0lU/yZHBvHFKYzMwsocvfPmNmngZuA0yOuKdecB2xz9/PNrBx4HvgB8DN3vyna0nKTmRUBuPu03batB/4e2Ag8aGYT3f25aCrMLe5eSTCQYmb/SjDQTgTmuPvvoqss95jZHOB8oDHc9DPgWnd/zMxuBU43s83ACcBxwMHA74BPRlFv1Lpor4XAN919vZldDnwPuJKgv53s7jXRVJo7umiziewx3ocBW32MD7eXu58dbi8DHgW+He46Dhjv7gP9+sVdZYr15Ng4pmUemZkCrAJw93XApGjLyUm/Ba7b7Xk7cCwww8weN7MlZlYSTWk56xNA0sxWm9kjZnY8UOjub4QD6UPA56MtMfeY2SSCfzaLCfrYxWb2hJndZGaaKAi8Afzdbs+PBTpn7FcCJxKMa6vdPe3ufwESZtbljQkGgD3b62x3Xx8+TgDvhd9QfhxYbGZPmtnF+7vIHNNVH9tzvFcfe9+e7dXpBuAWd68ys5FAKbDczNaa2Zf2a4W5ZW+ZIqfGMYXpzAzh/a/iATr0T/uD3L3B3XeGA+h9wLXAM8BV7n48wUzrvChrzEFNwALgZOAK4N/CbZ12AkMjqCvXzSX4BwTwMPBN4HhgMEE7DnjhTH3bbptiu810dfarPce1Advf9mwvd68CMLPJwGzg50AxwdKP84AvAl83s6P3f7W5oYs+1tV4rz4W6qK9MLMRBBMmleGmAoJvvmcRBO+fh/sMOHvJFDk3jilMZ2YHsPusatzd26MqJleZ2cEEX1f9u7vfA9zv7s+GL98PTIisuNz0KvCb8BP1qwQDwrDdXi8B6iOpLEeZWSlwhLs/Gm66w903hgPsf6E+tjep3R539qs9xzX1t92Y2VeAW4EZ7l5N8EF3obs3uftO4BGCb5ck0NV4rz62b18G7nH3jvD5FuBWd29393cJljZYZNVFrItMkXPjmMJ0Zp4ETgUI10y/GG05uSf8emo18D13vyPc/JCZfSp8/Hng2S4PHrguJpiFwMwOBJJAo5mNNbMYwYz1ExHWl4uOB/4IELbRC2Z2UPia+tjePW9m08LHpxD0qyeBk80sbmaHEEwSDPi1wABmdh7BjPQ0d98Ybj4cWGtmeeGPo6YA+j3D+7oa79XH9u1EguUKuz9fBmBmg4GjgJcjqCtye8kUOTeOaYlCZu4HTjKzp4AY8A8R15OL5gJlwHVm1rnO6UrgF2bWSvCJ+7KoistRS4BKM1tL8Ovkiwk+ed8N5BGsA/ufCOvLRUbwFTLunjazS4H/NLNmgl96/zrK4nLYd4Bfm1kBwT/n+9y9w8yeAJ4mmGD5RpQF5gozywNuBv5C0LcA1rj7PDO7G1hH8HX9Xe6+IbpKc87XgF/uPt67+w71sX3aNZ4BuPtKMzvZzNYR/C+YO4A/fHSVKf4RuDmXxrFYOj3QfygqIiIiIpIdLfMQEREREcmSwrSIiIiISJYUpkVEREREsqQwLSIiIiKSJYVpEREREZEs6dJ4IiJ9VHit1WUElwPsVO3uZ3bzvJXAUndf1Z3ziIgMBArTIiJ92yPufnbURYiIDFQK0yIi/YyZPQa8AhxBcIOpr7j7FjO7ieCOfRDcvnihmX0cuB0oILhVdmcwv9zM5gBDga+5+zP78z2IiPQVCtMiIn3b9DA8d3ow/PuUu19hZl8H5prZauAw4NMEY/9aM3sEmA/82N1XmdlZwITw+Gfdfb6ZXQRcBChMi4h0QWFaRKRv+9AyDzObATwSPn0KOB14C3jC3dNAW3ir4r8huJXx0wDuviw8/hzg2fD4LUCyt9+EiEhfpat5iIj0T8eGfz8LbABeJlziYWb5wGTgtXD7J8Pt55rZN8Pj0vu1WhGRPkoz0yIifdueyzwABgEXmdmVQCNwvrtvM7NpZvY0wfroZe7+nJldBdxmZtcSrJk+j/eDuIiIfIRYOq3JBxGR/iQM11e4+ytR1yIi0t9pmYeIiIiISJY0My0iIiIikiXNTIuIiIiIZElhWkREREQkSwrTIiIiIiJZUpgWEREREcmSwrSIiIiISJYUpkVEREREsvT/ZvIcCnsJeqYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history,'accuracy','val_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já no que toca à curva da *loss*, é notório que o valor desce de forma adequada à medida que o treino é efetuado, não apresentando sinais de *overfitting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar o modelo treinado, é necessário separar o conjunto de teste em *features* e *labels*, tal como aconteceu com o conjunto de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = teste.loc[:, teste.columns != 'LABEL']\n",
    "x_test = X.values\n",
    "Y = teste['LABEL']\n",
    "\n",
    "# One Hot Encoding\n",
    "y_test = to_categorical(Y.values)\n",
    "y_test = y_test[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo em conta o armazenamento do melhor modelo, este deve ser carregado numa variável para o teste dos dados ser efetuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efetuada a previsão do conjunto de teste, tendo em conta que as variáveis de decisão são categóricas, estas têm que ser convertidas de modo a ser efetuada uma comparação com os valores reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "test_preds = model.predict_classes(x_test)\n",
    "test_preds = to_categorical(test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando as métricas, é possível constatar que a métrica de precisão na classe minoritária é 0.0, tal como o *recall*, pelo que este tipo de modelo não parece ser o mais apropriado para tratar dados em que a ordem de ocorrência dos dados acontece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       565\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       570\n",
      "   macro avg       0.50      0.50      0.50       570\n",
      "weighted avg       0.98      0.99      0.99       570\n",
      " samples avg       0.99      0.99      0.99       570\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.987719298245614"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))\n",
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pela análise das matrizes de confusão de ambas as classes, é visível que o modelo não classificou corretamente nenhum dos 5 sistemas com exoplanetas. É, também, importante mencionar que classificou de forma errada 2 sistemas como possuindo exoplanetas. Talvez com algum aperfeiçoamento este modelo mostrasse melhores resultados. No entanto, não é um modelo aconselhado aquando do tratamento de dados temporais, segundo a literatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   5],\n",
       "        [  2, 563]],\n",
       "\n",
       "       [[563,   2],\n",
       "        [  5,   0]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
