{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Aprendizagem Automática II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procura de Exoplanetas no Espaço através da Emissão de Luz de Estrelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib            \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pd.read_csv(\"../../../Dados/dados_treino.csv\")\n",
    "teste = pd.read_csv(\"../../../Dados/dados_teste.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo é a preparação dos dados para o tipo de rede que se está a criar. Assim, tendo em conta que será utilizado o método *GridSearchCV*, este apenas recebe um *array* de *features* e outro de *labels*, ambos unidimensionais, não pode ser efetuado o *reshape* dos dados neste passo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = treino['LABEL']\n",
    "X = treino.loc[:, treino.columns != 'LABEL']\n",
    "X_train = X.values#.reshape(-1, X.shape[1], 1)\n",
    "\n",
    "Yt = teste['LABEL']\n",
    "Xt = teste.loc[:, teste.columns != 'LABEL']\n",
    "X_test = Xt.values#.reshape(-1, Xt.shape[1], 1)\n",
    "\n",
    "# One Hot Encoding\n",
    "y_train = to_categorical(Y.values)\n",
    "y_train = y_train[:, 1:]\n",
    "\n",
    "y_test = to_categorical(Yt.values)\n",
    "y_test = y_test[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez, tendo em conta a utilização do método *GridSearchCV*, foi necessária a definição de uma função para criar e retornar o modelo, com base em certos parâmetros, nomeadamente a taxa de aprendizagem e a probabilidade de *dropout*. Além disso, o modelo difere do original na medida em que possui uma camada inicial de *reshape* dos dados, devido às restrições no formato de dados do método de pesquisa em grelha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "def create_model(learn_rate = 0.001, dropout = 0.25):\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((3198, 1)))\n",
    "    model.add(Conv1D(filters=16, kernel_size=16, activation='relu', input_shape=(3198, 1)))\n",
    "    model.add(MaxPool1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learn_rate), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criar um modelo, é necessário instanciar uma variável como um *KerasClassifier*, sendo construído com base na função definida anteriormente para gerar um modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma a otimizar os parâmetros do modelo, estes devem ser definidos na forma de dicionário. Neste caso, optou-se pelo teste de várias combinações, vendo qual a que melhores resultados traria ao problema. Assim, foram testados os impactos de parâmetros como *batch_size*, número de épocas, taxa de aprendizagem e probabilidade de *dropout*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {\n",
    "    'batch_size': [64, 128, 256],\n",
    "    'epochs': [10, 15, 20],\n",
    "    'learn_rate': [0.001, 0.01, 0.0005, 0.0001, 0.00005, 0.00001],\n",
    "    'dropout' : [0.0, 0.1, 0.2, 0.25]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo a testar cada caso na grelha, foi definida uma métrica personalizada, permitindo comparar os valores reais com os calculados, retornando a *accuracy* dos cálculos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def custom_metric(y_true, y_predicted):\n",
    "    return accuracy_score(y_true.argmax(axis=-1), y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além da definição da função para a métrica, é, ainda, fundamental definir como *scorer* a função e qual a orientação ideal para os resultados, ou seja, se quanto mais elevado melhor, ou o oposto. Neste caso, quanto mais elevada a *accuracy*, melhor o modelo testado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "custom_score = make_scorer(custom_metric, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mencionado anteriormente, foi tirado proveito do método *GridSearchCV*, permitindo uma pesquisa em grelha dentro das combinações de parâmetros pretendidas, em que exista uma validação em cruz. Neste caso, optou-se por uma validação cruzada de 3 subconjuntos, devido ao elevado peso computacional dos modelos, sendo utilizada como métrica de *scoring* a função definida em cima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=parametros, n_jobs=-1, cv=3, scoring=custom_score, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo a grelha definida e pronta a efetuar a procura, apenas é necessário aplicar o método *fit* com o conjunto de dados de treino. Não faria sentido aplicar a validação cruzada aos dados de teste juntamente com os de treino, já que o modelo ficaria demasiado ajustado aos dados, perdendo a capacidade de classificar corretamente novos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 48.0min\n",
      "C:\\Users\\jonyp\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 307.9min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 669.1min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 1104.6min\n",
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed: 1131.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6565/6565 [==============================] - 11s 2ms/step - loss: 0.1449 - accuracy: 0.9438\n",
      "Epoch 2/20\n",
      "6565/6565 [==============================] - 10s 2ms/step - loss: 0.0123 - accuracy: 0.9959\n",
      "Epoch 3/20\n",
      "6565/6565 [==============================] - 10s 2ms/step - loss: 0.0099 - accuracy: 0.9973\n",
      "Epoch 4/20\n",
      "6565/6565 [==============================] - 10s 2ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 5/20\n",
      "6565/6565 [==============================] - 10s 2ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "Epoch 6/20\n",
      "6565/6565 [==============================] - 10s 2ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 7/20\n",
      "6565/6565 [==============================] - 11s 2ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 8/20\n",
      "6565/6565 [==============================] - 10s 2ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 9/20\n",
      "6565/6565 [==============================] - 11s 2ms/step - loss: 0.0060 - accuracy: 0.9973\n",
      "Epoch 10/20\n",
      "6565/6565 [==============================] - 10s 2ms/step - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 11/20\n",
      "6565/6565 [==============================] - 10s 2ms/step - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 12/20\n",
      "6565/6565 [==============================] - 11s 2ms/step - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 13/20\n",
      "6565/6565 [==============================] - 11s 2ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 14/20\n",
      "6565/6565 [==============================] - 11s 2ms/step - loss: 0.0025 - accuracy: 0.9989\n",
      "Epoch 15/20\n",
      "6565/6565 [==============================] - 11s 2ms/step - loss: 0.0034 - accuracy: 0.9985\n",
      "Epoch 16/20\n",
      "6565/6565 [==============================] - 10s 2ms/step - loss: 0.0089 - accuracy: 0.9970\n",
      "Epoch 17/20\n",
      "6565/6565 [==============================] - 11s 2ms/step - loss: 0.0056 - accuracy: 0.9979\n",
      "Epoch 18/20\n",
      "6565/6565 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 19/20\n",
      "6565/6565 [==============================] - 10s 2ms/step - loss: 0.0031 - accuracy: 0.9988\n",
      "Epoch 20/20\n",
      "6565/6565 [==============================] - 11s 2ms/step - loss: 0.0020 - accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o método *get_params* é possível observar os vários parâmetros associados à pesquisa efetuada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 3,\n",
       " 'error_score': nan,\n",
       " 'estimator__verbose': 1,\n",
       " 'estimator__build_fn': <function __main__.create_model(learn_rate=0.001, dropout=0.25)>,\n",
       " 'estimator': <keras.wrappers.scikit_learn.KerasClassifier at 0x1a4ce2ddd88>,\n",
       " 'iid': 'deprecated',\n",
       " 'n_jobs': -1,\n",
       " 'param_grid': {'batch_size': [64, 128, 256],\n",
       "  'epochs': [10, 15, 20],\n",
       "  'learn_rate': [0.001, 0.01, 0.0005, 0.0001, 5e-05, 1e-05],\n",
       "  'dropout': [0.0, 0.1, 0.2, 0.25]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': make_scorer(custom_metric),\n",
       " 'verbose': 2}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se pode ver de seguida, os melhores parâmetros de entre os testados são *batch_size* com tamanho 256, ou seja, a cada iteração, a rede é treinada com 256 registos. Além disso, o número de épocas que permitiu os melhores resultados foi 20. No que toca aos parâmetros da função de criação do modelo, o valor de *dropout* foi de 20%, querendo isto dizer que a cada fase existe uma probabilidade de 20% de cada neurónio ser desativado. Já a taxa de aprendizagem tomou o valor de 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 256, 'dropout': 0.2, 'epochs': 20, 'learn_rate': 0.0001}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor resultado obtido para a pesquisa em grelha, com os parâmetros acima mencionados, permitiu uma *accuracy* de sensivelmente 96.1%. Note-se que este valor está associado a uma validação cruzada com 3 subconjuntos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9606951855282172"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conhecidos os melhores parâmetros para este modelo, é necessário ver de que forma se comporta na classificação do conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 623us/step\n"
     ]
    }
   ],
   "source": [
    "preds = grid_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo a comparar os resultados, de forma mais fácil, com as *labels* reais, as previsões foram convertidas em registos categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = to_categorical(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando as métricas obtidas pela predição dos registos de teste, é notório que a precisão da classe minoritária desceu quando em comparação com o modelo original (o qual tinha valor de 67%). Além disso, também o *recall* baixou, passando de 80% para 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       565\n",
      "           1       0.60      0.60      0.60         5\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       570\n",
      "   macro avg       0.80      0.80      0.80       570\n",
      "weighted avg       0.99      0.99      0.99       570\n",
      " samples avg       0.99      0.99      0.99       570\n",
      "\n",
      "accuracy: 0.9929824561403509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"accuracy:\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando as matrizes de confusão e, mais uma vez, comparando com o modelo original, verifica-se que foram classificados 3 dos 5 sistemas da classe minoritária corretamente, ao invés de 4 em 5 registos, como originalmente alcançado. No que toca a classificações erradas de sistemas da classe maioritária, em ambos os modelos foram classificados incorretamente apenas 2 registos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  3,   2],\n",
       "        [  2, 563]],\n",
       "\n",
       "       [[563,   2],\n",
       "        [  2,   3]]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em jeito de conclusão, a otimização do modelo não trouxe uma melhoria na classificação dos registos da classe minoritária, como esperado. No entanto, tendo em conta a quantidade reduzida de registos da classe minoritária, a diferença entre este modelo e o original é bastante pequena. Desta forma, não é possível afirmar com certeza que um modelo é superior ao outro. Apesar disso, tendo em conta a utilização de uma pesquisa em grelha com validação cruzada sobre o conjunto de treino, os parâmetros deste modelo permitiram a obtenção de melhores resultados, sendo possível afirmar que este modelo permite uma melhor classificação no panorama geral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
